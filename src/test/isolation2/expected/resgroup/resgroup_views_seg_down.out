-- The test below checks that FTS can break the stuck cancelled/terminated
-- query, if one of the segments has hanged.
-- Original problem was:
-- 1. For some reason (the reason itself is not important) at some point segment hangs.
-- 2. Query to 'gp_resgroup_status_per_segment' also hangs.
-- 3. If 'pg_cancel_backend' or 'pg_terminate_backend' is called before FTS makes
-- promotion, the query stays is stuck condition.

-- Change FTS settings to make FTS probe work faster in the test.
!\retcode gpconfig -c gp_fts_probe_timeout -v 5 --masteronly;
(exited with code 0)
!\retcode gpconfig -c gp_fts_probe_retries -v 1 --masteronly;
(exited with code 0)
!\retcode gpstop -u;
(exited with code 0)

CREATE EXTENSION IF NOT EXISTS gp_inject_fault;
CREATE

include: helpers/server_helpers.sql;
CREATE

-- Case 1: check the scenario with 'pg_cancel_backend'.

-- Reset FTS probe interval.
SELECT gp_request_fts_probe_scan();
 gp_request_fts_probe_scan 
---------------------------
 t                         
(1 row)

-- Make a successfull query to allocate query executer backends on the segments.
1:SELECT count(1) FROM gp_toolkit.gp_resgroup_status_per_segment WHERE rsgname = 'default_group';
 count 
-------
 4     
(1 row)

-- Emulate hanged segment condition:
-- 0. Store the name of datadir for seg0 - we will need it on step 2.
-- 1. Stop the backends from processing requests by injecting a fault.
-- 2. Stop segment postmaster process. This can't be done by the fault injection,
-- as we wouldn't be able to recover the postmaster back to life in this case.
-- Thus do it by sending a STOP signal. We need to do it on all segments (not on
-- the coordinator), as the segment process may be running on a separate machine.
2: @post_run 'get_tuple_cell DATADIR 1 1': SELECT datadir FROM gp_segment_configuration WHERE role = 'p' AND content = 0;

SELECT gp_inject_fault('exec_simple_query_start', 'suspend', dbid) FROM gp_segment_configuration WHERE role = 'p' AND content = 0;
 gp_inject_fault 
-----------------
 Success:        
(1 row)

2: @pre_run ' echo "${RAW_STR}" | sed "s#@DATADIR#${DATADIR}#" ': SELECT exec_cmd_on_segments('ps aux | grep ''@DATADIR'' | awk ''FNR == 1 {print $2; exit}'' | xargs kill -STOP');
 exec_cmd_on_segments 
----------------------
 OK                   
 OK                   
 OK                   
(3 rows)

-- Launch the query again, now it will hang.
1&:SELECT count(1) FROM gp_toolkit.gp_resgroup_status_per_segment WHERE rsgname = 'default_group';  <waiting ...>

-- Cancel the hanging query.
SELECT pg_cancel_backend(pid) FROM pg_stat_activity WHERE query = 'SELECT count(1) FROM gp_toolkit.gp_resgroup_status_per_segment WHERE rsgname = ''default_group'';';
 pg_cancel_backend 
-------------------
 t                 
(1 row)

-- Trigger FTS scan.
SELECT gp_request_fts_probe_scan();
 gp_request_fts_probe_scan 
---------------------------
 t                         
(1 row)

-- Expect to see the content 0, preferred primary is mirror and it is down,
-- the preferred mirror is primary
SELECT content, preferred_role, role, status, mode FROM gp_segment_configuration WHERE content = 0;
 content | preferred_role | role | status | mode 
---------+----------------+------+--------+------
 0       | p              | m    | d      | n    
 0       | m              | p    | u      | n    
(2 rows)

-- Check that no locks are left from the query, meaning it ended completely.
SELECT * FROM pg_locks WHERE mode = 'ExclusiveLock' AND locktype = 'relation';
 locktype | database | relation | page | tuple | virtualxid | transactionid | classid | objid | objsubid | virtualtransaction | pid | mode | granted | fastpath | mppsessionid | mppiswriter | gp_segment_id 
----------+----------+----------+------+-------+------------+---------------+---------+-------+----------+--------------------+-----+------+---------+----------+--------------+-------------+---------------
(0 rows)

-- Recover back the segment
2: @pre_run ' echo "${RAW_STR}" | sed "s#@DATADIR#${DATADIR}#" ': SELECT exec_cmd_on_segments('ps aux | grep ''@DATADIR'' | awk ''FNR == 1 {print $2; exit}'' | xargs kill -CONT');
 exec_cmd_on_segments 
----------------------
 OK                   
 OK                   
 OK                   
(3 rows)

SELECT gp_inject_fault('exec_simple_query_start', 'resume', dbid) FROM gp_segment_configuration WHERE role = 'm' AND content = 0;
 gp_inject_fault 
-----------------
 Success:        
(1 row)

SELECT gp_inject_fault('exec_simple_query_start', 'reset', dbid) FROM gp_segment_configuration WHERE role = 'm' AND content = 0;
 gp_inject_fault 
-----------------
 Success:        
(1 row)

-- Fully recover the failed primary as new mirror.
!\retcode gprecoverseg -aF --no-progress;
(exited with code 0)

-- Wait while segments come in sync.
SELECT wait_until_all_segments_synchronized();
 wait_until_all_segments_synchronized 
--------------------------------------
 OK                                   
(1 row)

-- Expect to see roles flipped and in sync.
SELECT content, preferred_role, role, status, mode FROM gp_segment_configuration WHERE content = 0;
 content | preferred_role | role | status | mode 
---------+----------------+------+--------+------
 0       | m              | p    | u      | s    
 0       | p              | m    | u      | s    
(2 rows)

!\retcode gprecoverseg -ar;
(exited with code 0)

-- Wait while segments come in sync.
SELECT wait_until_all_segments_synchronized();
 wait_until_all_segments_synchronized 
--------------------------------------
 OK                                   
(1 row)

-- Verify that no segment is down after the recovery.
SELECT count(*) FROM gp_segment_configuration WHERE status = 'd';
 count 
-------
 0     
(1 row)

1<:  <... completed>
ERROR:  canceling statement due to user request

-- Case 2: check the scenario with 'pg_terminate_backend'.

-- Reset FTS probe interval.
SELECT gp_request_fts_probe_scan();
 gp_request_fts_probe_scan 
---------------------------
 t                         
(1 row)

-- Make a successfull query to allocate query executer backends on the segments.
1:SELECT count(1) FROM gp_toolkit.gp_resgroup_status_per_segment WHERE rsgname = 'default_group';
 count 
-------
 4     
(1 row)

-- Emulate hanged segment condition:
-- 1. Stop the backends from processing requests by injecting a fault.
-- 2. Stop segment postmaster process. This can't be done by the fault injection,
-- as we wouldn't be able to recover the postmaster back to life in this case.
-- Thus do it by sending a STOP signal. We need to do it on all segments (not on
-- the coordinator), as the segment process may be running on a separate machine.
SELECT gp_inject_fault('exec_simple_query_start', 'suspend', dbid) FROM gp_segment_configuration WHERE role = 'p' AND content = 0;
 gp_inject_fault 
-----------------
 Success:        
(1 row)

2: @pre_run ' echo "${RAW_STR}" | sed "s#@DATADIR#${DATADIR}#" ': SELECT exec_cmd_on_segments('ps aux | grep ''@DATADIR'' | awk ''FNR == 1 {print $2; exit}'' | xargs kill -STOP');
 exec_cmd_on_segments 
----------------------
 OK                   
 OK                   
 OK                   
(3 rows)

-- Launch the query again, now it will hang.
1&:SELECT count(1) FROM gp_toolkit.gp_resgroup_status_per_segment WHERE rsgname = 'default_group';  <waiting ...>

-- Terminate the hanging query.
SELECT pg_terminate_backend(pid) FROM pg_stat_activity WHERE query = 'SELECT count(1) FROM gp_toolkit.gp_resgroup_status_per_segment WHERE rsgname = ''default_group'';';
 pg_terminate_backend 
----------------------
 t                    
(1 row)

-- Trigger FTS scan.
SELECT gp_request_fts_probe_scan();
 gp_request_fts_probe_scan 
---------------------------
 t                         
(1 row)

-- Expect to see the content 0, preferred primary is mirror and it is down,
-- the preferred mirror is primary
SELECT content, preferred_role, role, status, mode FROM gp_segment_configuration WHERE content = 0;
 content | preferred_role | role | status | mode 
---------+----------------+------+--------+------
 0       | p              | m    | d      | n    
 0       | m              | p    | u      | n    
(2 rows)

-- Check that no locks are left from the query, meaning it ended completely.
SELECT * FROM pg_locks WHERE mode = 'ExclusiveLock' AND locktype = 'relation';
 locktype | database | relation | page | tuple | virtualxid | transactionid | classid | objid | objsubid | virtualtransaction | pid | mode | granted | fastpath | mppsessionid | mppiswriter | gp_segment_id 
----------+----------+----------+------+-------+------------+---------------+---------+-------+----------+--------------------+-----+------+---------+----------+--------------+-------------+---------------
(0 rows)

-- Recover back the segment
2: @pre_run ' echo "${RAW_STR}" | sed "s#@DATADIR#${DATADIR}#" ': SELECT exec_cmd_on_segments('ps aux | grep ''@DATADIR'' | awk ''FNR == 1 {print $2; exit}'' | xargs kill -CONT');
 exec_cmd_on_segments 
----------------------
 OK                   
 OK                   
 OK                   
(3 rows)

SELECT gp_inject_fault('exec_simple_query_start', 'resume', dbid) FROM gp_segment_configuration WHERE role = 'm' AND content = 0;
 gp_inject_fault 
-----------------
 Success:        
(1 row)

SELECT gp_inject_fault('exec_simple_query_start', 'reset', dbid) FROM gp_segment_configuration WHERE role = 'm' AND content = 0;
 gp_inject_fault 
-----------------
 Success:        
(1 row)

-- Fully recover the failed primary as new mirror.
!\retcode gprecoverseg -aF --no-progress;
(exited with code 0)

-- Wait while segments come in sync.
SELECT wait_until_all_segments_synchronized();
 wait_until_all_segments_synchronized 
--------------------------------------
 OK                                   
(1 row)

-- Expect to see roles flipped and in sync.
SELECT content, preferred_role, role, status, mode FROM gp_segment_configuration WHERE content = 0;
 content | preferred_role | role | status | mode 
---------+----------------+------+--------+------
 0       | m              | p    | u      | s    
 0       | p              | m    | u      | s    
(2 rows)

!\retcode gprecoverseg -ar;
(exited with code 0)

-- Wait while segments come in sync.
SELECT wait_until_all_segments_synchronized();
 wait_until_all_segments_synchronized 
--------------------------------------
 OK                                   
(1 row)

-- Verify that no segment is down after the recovery.
SELECT count(*) FROM gp_segment_configuration WHERE status = 'd';
 count 
-------
 0     
(1 row)

1<:  <... completed>
FATAL:  terminating connection due to administrator command
server closed the connection unexpectedly
	This probably means the server terminated abnormally
	before or while processing the request.
1q: ... <quitting>

-- Restore parameters.
!\retcode gpconfig -r gp_fts_probe_timeout --masteronly;
(exited with code 0)
!\retcode gpconfig -r gp_fts_probe_retries --masteronly;
(exited with code 0)
!\retcode gpstop -u;
(exited with code 0)

