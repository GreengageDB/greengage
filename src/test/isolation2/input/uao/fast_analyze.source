--
-- Test AO/CO sampling method.
--
-- These tests ensure that we achieve our ANALYZE targets for AO/CO tables.
--
CREATE TABLE fast_analyze_@amname@_1(i int, j int) USING @amname@ DISTRIBUTED BY (j);

-- Stats target info shows that we will sample 300 * (100) rows.
SHOW default_statistics_target;
SELECT attstattarget FROM pg_attribute
  WHERE attrelid = 'fast_analyze_@amname@_1'::regclass AND attname IN ('i', 'j');

--------------------------------------------------------------------------------
-- Scenario 1:
-- We have MORE than 300 * default_statistics_target = 30k rows for a 2 int table,
-- spread across 3 segments, with no aborted rows [2 subcases -> blkdir and
-- non-blkdir].
-- Expectation: We have collected 30k live rows.
--------------------------------------------------------------------------------

-- (a) Without blkdir subcase

-- Insert 10.5k rows in each QE.
1: BEGIN;
2: BEGIN;
3: BEGIN;
1: INSERT INTO fast_analyze_@amname@_1 SELECT i, 2 FROM generate_series(1, 10500) i;
2: INSERT INTO fast_analyze_@amname@_1 SELECT i, 1 FROM generate_series(1, 10500) i;
3: INSERT INTO fast_analyze_@amname@_1 SELECT i, 5 FROM generate_series(1, 10500) i;
1: COMMIT;
2: COMMIT;
3: COMMIT;

-- make sure new column does not affect the result
ALTER TABLE fast_analyze_@amname@_1 ADD COLUMN newcol int;

SELECT gp_inject_fault_infinite('returned_sample_row', 'skip', dbid)
  FROM gp_segment_configuration WHERE content != -1 AND role = 'p';

ANALYZE fast_analyze_@amname@_1;

-- We have sampled 10k live rows.
SELECT gp_inject_fault('returned_sample_row', 'status', dbid)
  FROM gp_segment_configuration WHERE content != -1 AND role = 'p';

SELECT gp_inject_fault('returned_sample_row', 'reset', dbid)
  FROM gp_segment_configuration WHERE content != -1 AND role = 'p';

-- (b) With blkdir subcase

CREATE INDEX ON fast_analyze_@amname@_1(i);

SELECT gp_inject_fault_infinite('returned_sample_row', 'skip', dbid)
  FROM gp_segment_configuration WHERE content != -1 AND role = 'p';

ANALYZE fast_analyze_@amname@_1;

-- We have sampled 10k live rows from each QE.
SELECT gp_inject_fault('returned_sample_row', 'status', dbid)
  FROM gp_segment_configuration WHERE content != -1 AND role = 'p';

SELECT gp_inject_fault('returned_sample_row', 'reset', dbid)
  FROM gp_segment_configuration WHERE content != -1 AND role = 'p';

--------------------------------------------------------------------------------
-- Scenario 2:
-- We have LESS than 300 * default_statistics_target = 30k rows for a 2 int table,
-- spread across 3 segments, with no aborted rows [2 subcases -> blkdir and
-- non-blkdir].
-- Expectation: We have collected number of live rows = total tupcount of table.
--------------------------------------------------------------------------------

CREATE TABLE fast_analyze_@amname@_2(i int, j int) USING @amname@ DISTRIBUTED BY (j);

-- (a) Without blkdir subcase

-- Insert 10 rows in each QE.
1: BEGIN;
2: BEGIN;
3: BEGIN;
1: INSERT INTO fast_analyze_@amname@_2 SELECT i, 2 FROM generate_series(1, 10) i;
2: INSERT INTO fast_analyze_@amname@_2 SELECT i, 1 FROM generate_series(1, 10) i;
3: INSERT INTO fast_analyze_@amname@_2 SELECT i, 5 FROM generate_series(1, 10) i;
1: COMMIT;
2: COMMIT;
3: COMMIT;

-- make sure new column does not affect the result
ALTER TABLE fast_analyze_@amname@_2 ADD COLUMN newcol int;

SELECT gp_inject_fault_infinite('returned_sample_row', 'skip', dbid)
  FROM gp_segment_configuration WHERE content != -1 AND role = 'p';

ANALYZE fast_analyze_@amname@_2;

-- We have sampled 10 live rows from each QE.
SELECT gp_inject_fault('returned_sample_row', 'status', dbid)
  FROM gp_segment_configuration WHERE content != -1 AND role = 'p';

SELECT gp_inject_fault('returned_sample_row', 'reset', dbid)
  FROM gp_segment_configuration WHERE content != -1 AND role = 'p';

-- (b) With blkdir subcase

CREATE INDEX ON fast_analyze_@amname@_2(i);

SELECT gp_inject_fault_infinite('returned_sample_row', 'skip', dbid)
  FROM gp_segment_configuration WHERE content != -1 AND role = 'p';

ANALYZE fast_analyze_@amname@_2;

-- We have sampled 10 live rows from each QE.
SELECT gp_inject_fault('returned_sample_row', 'status', dbid)
  FROM gp_segment_configuration WHERE content != -1 AND role = 'p';

SELECT gp_inject_fault('returned_sample_row', 'reset', dbid)
  FROM gp_segment_configuration WHERE content != -1 AND role = 'p';

--------------------------------------------------------------------------------
-- Scenario 3:
-- We have ALL aborted rows [2 subcases -> blkdir and non-blkdir].
-- Expectation: We have not sampled any live rows.
--------------------------------------------------------------------------------

CREATE TABLE fast_analyze_@amname@_3(i int, j int) USING @amname@ DISTRIBUTED BY (j);

-- (a) Without blkdir subcase

-- Insert 10 rows in each QE.
1: BEGIN;
2: BEGIN;
3: BEGIN;
1: INSERT INTO fast_analyze_@amname@_3 SELECT i, 2 FROM generate_series(1, 10) i;
2: INSERT INTO fast_analyze_@amname@_3 SELECT i, 1 FROM generate_series(1, 10) i;
3: INSERT INTO fast_analyze_@amname@_3 SELECT i, 5 FROM generate_series(1, 10) i;
1: ABORT;
2: ABORT;
3: ABORT;

-- make sure new column does not affect the result
ALTER TABLE fast_analyze_@amname@_3 ADD COLUMN newcol int;

SELECT gp_inject_fault_infinite('returned_sample_row', 'skip', dbid)
  FROM gp_segment_configuration WHERE content != -1 AND role = 'p';

ANALYZE fast_analyze_@amname@_3;

-- We have not sampled any live rows on any QE.
SELECT gp_inject_fault('returned_sample_row', 'status', dbid)
  FROM gp_segment_configuration WHERE content != -1 AND role = 'p';

SELECT gp_inject_fault('returned_sample_row', 'reset', dbid)
  FROM gp_segment_configuration WHERE content != -1 AND role = 'p';

-- (b) With blkdir subcase

CREATE INDEX ON fast_analyze_@amname@_3(i);

SELECT gp_inject_fault_infinite('returned_sample_row', 'skip', dbid)
  FROM gp_segment_configuration WHERE content != -1 AND role = 'p';

ANALYZE fast_analyze_@amname@_3;

-- We have not sampled any live rows on any QE.
SELECT gp_inject_fault('returned_sample_row', 'status', dbid)
  FROM gp_segment_configuration WHERE content != -1 AND role = 'p';

SELECT gp_inject_fault('returned_sample_row', 'reset', dbid)
  FROM gp_segment_configuration WHERE content != -1 AND role = 'p';

--------------------------------------------------------------------------------
-- Scenario 4:
-- We have ALL deleted rows [2 subcases -> blkdir and non-blkdir].
-- Expectation: We have not collected any live rows.
--------------------------------------------------------------------------------

CREATE TABLE fast_analyze_@amname@_4(i int, j int) USING @amname@ DISTRIBUTED BY (j);

-- (a) Without blkdir subcase

-- Insert 10 rows in each QE.
1: BEGIN;
2: BEGIN;
3: BEGIN;
1: INSERT INTO fast_analyze_@amname@_4 SELECT i, 2 FROM generate_series(1, 10) i;
2: INSERT INTO fast_analyze_@amname@_4 SELECT i, 1 FROM generate_series(1, 10) i;
3: INSERT INTO fast_analyze_@amname@_4 SELECT i, 5 FROM generate_series(1, 10) i;
1: COMMIT;
2: COMMIT;
3: COMMIT;
-- Delete all rows.
DELETE FROM fast_analyze_@amname@_4;
SELECT gp_inject_fault_infinite('returned_sample_row', 'skip', dbid)
  FROM gp_segment_configuration WHERE content != -1 AND role = 'p';

-- make sure new column does not affect the result
ALTER TABLE fast_analyze_@amname@_4 ADD COLUMN newcol int;

ANALYZE fast_analyze_@amname@_4;

-- We have not sampled any live rows on any QE.
SELECT gp_inject_fault('returned_sample_row', 'status', dbid)
  FROM gp_segment_configuration WHERE content != -1 AND role = 'p';

SELECT gp_inject_fault('returned_sample_row', 'reset', dbid)
  FROM gp_segment_configuration WHERE content != -1 AND role = 'p';

-- (b) With blkdir subcase

CREATE INDEX ON fast_analyze_@amname@_4(i);

SELECT gp_inject_fault_infinite('returned_sample_row', 'skip', dbid)
  FROM gp_segment_configuration WHERE content != -1 AND role = 'p';

ANALYZE fast_analyze_@amname@_4;

-- We have not sampled any live rows on any QE.
SELECT gp_inject_fault('returned_sample_row', 'status', dbid)
  FROM gp_segment_configuration WHERE content != -1 AND role = 'p';

SELECT gp_inject_fault('returned_sample_row', 'reset', dbid)
  FROM gp_segment_configuration WHERE content != -1 AND role = 'p';

DROP TABLE fast_analyze_@amname@_1;
DROP TABLE fast_analyze_@amname@_2;
DROP TABLE fast_analyze_@amname@_3;
DROP TABLE fast_analyze_@amname@_4;

--
-- The following tests ensure fast analyze function to work
-- with multi-segfiles tables under concurrent inserts.
--

create table analyze_@amname@ (id int, a int, b inet, c inet) using @amname@ with (compresstype=zlib, compresslevel=3);

insert into analyze_@amname@ select 2, i, (select ((i%255)::text || '.' || (i%255)::text || '.' || (i%255)::text || '.' ||
  (i%255)::text))::inet, (select ((i%255)::text || '.' || (i%255)::text || '.' || (i%255)::text || '.' ||
  (i%255)::text))::inet from generate_series(1,30000)i;

insert into analyze_@amname@ select * from analyze_@amname@ limit 1000;
insert into analyze_@amname@ select * from analyze_@amname@ limit 1000;

-- test ANALYZE after concurrent inserts commit

1: begin;
1: insert into analyze_@amname@ select * from analyze_@amname@ limit 1000;

2: begin;
2: insert into analyze_@amname@ select * from analyze_@amname@ limit 1000;

3: begin;
3: insert into analyze_@amname@ select * from analyze_@amname@ limit 1000;

4: insert into analyze_@amname@ select * from analyze_@amname@ limit 1000;

5: analyze analyze_@amname@;

1: commit;
2: commit;
3: abort;

1: analyze analyze_@amname@;

-- test aoblkdir based ANALYZE

create index on analyze_@amname@(id);

1: begin;
1: insert into analyze_@amname@ select * from analyze_@amname@ limit 1000;

2: begin;
2: insert into analyze_@amname@ select * from analyze_@amname@ limit 1000;

3: begin;
3: insert into analyze_@amname@ select * from analyze_@amname@ limit 1000;

4: insert into analyze_@amname@ select * from analyze_@amname@ limit 1000;

5: analyze analyze_@amname@;

1: commit;
2: commit;
3: abort;

1: analyze analyze_@amname@;

drop table analyze_@amname@;

-- test more data and stability, note, it could take a little long time

create table analyze_@amname@_2 (id int, a int, b inet, c inet) using @amname@ with (compresstype=zlib, compresslevel=3);
insert into analyze_@amname@_2 select 2, i, (select ((i%255)::text || '.' || (i%255)::text || '.' || (i%255)::text || '.' ||
  (i%255)::text))::inet, (select ((i%255)::text || '.' || (i%255)::text || '.' || (i%255)::text || '.' ||
  (i%255)::text))::inet from generate_series(1,1000)i;

insert into analyze_@amname@_2 select * from analyze_@amname@_2;
insert into analyze_@amname@_2 select * from analyze_@amname@_2;
insert into analyze_@amname@_2 select * from analyze_@amname@_2;
insert into analyze_@amname@_2 select * from analyze_@amname@_2;
insert into analyze_@amname@_2 select * from analyze_@amname@_2;
insert into analyze_@amname@_2 select * from analyze_@amname@_2;
insert into analyze_@amname@_2 select * from analyze_@amname@_2;
insert into analyze_@amname@_2 select * from analyze_@amname@_2;

1: begin;
1: insert into analyze_@amname@_2 select * from analyze_@amname@_2;

2: insert into analyze_@amname@_2 select * from analyze_@amname@_2;

1: commit;

1: analyze analyze_@amname@_2;
1: analyze analyze_@amname@_2;
1: analyze analyze_@amname@_2;
1: analyze analyze_@amname@_2;
1: analyze analyze_@amname@_2;

1: begin;
1: insert into analyze_@amname@_2 select * from analyze_@amname@_2;

2: insert into analyze_@amname@_2 select * from analyze_@amname@_2;

1: abort;

1: analyze analyze_@amname@_2;
1: analyze analyze_@amname@_2;
1: analyze analyze_@amname@_2;
1: analyze analyze_@amname@_2;
1: analyze analyze_@amname@_2;

-- test with aoblkdir

create index on analyze_@amname@_2(a);

1: begin;
1: insert into analyze_@amname@_2 select * from analyze_@amname@_2;

2: insert into analyze_@amname@_2 select * from analyze_@amname@_2;

1: commit;

1: analyze analyze_@amname@_2;
1: analyze analyze_@amname@_2;
1: analyze analyze_@amname@_2;
1: analyze analyze_@amname@_2;
1: analyze analyze_@amname@_2;

1: begin;
1: insert into analyze_@amname@_2 select * from analyze_@amname@_2;

2: insert into analyze_@amname@_2 select * from analyze_@amname@_2;

1: abort;

1: analyze analyze_@amname@_2;
1: analyze analyze_@amname@_2;
1: analyze analyze_@amname@_2;
1: analyze analyze_@amname@_2;
1: analyze analyze_@amname@_2;

drop table analyze_@amname@_2;

--
-- The following test ensures ANALYZE won't break column correlation
-- as well as other pg_stats values. This is because we don't allow
-- caching minipage entry on ANALYZE AOCO table currently, misuse of
-- caching minipage entry for a specific column in ANALYZE AOCO table
-- could break column correlation which would impact cost estimation
-- and then finally resut in wrong plan to be selected.
--

create table analyze_@amname@_3(inttype int, texttype text, decimaltype decimal(10,2)) using @amname@;
insert into analyze_@amname@_3 select i, 'texttype'||i, i from generate_series(1,9999) i;
create index i_analyze_@amname@_3 on analyze_@amname@_3(inttype) include (texttype);
analyze analyze_@amname@_3;
select attname, correlation from pg_stats where tablename='analyze_@amname@_3';

drop table analyze_@amname@_3;

--
-- Test dead values returned in sampling CO tuples.
-- Non-blkdir based sampling had the following bug:
-- 
-- If you have 3 rows: (i,j) = (1, 1), (1, 2) and (1,3),
-- if (1, 2) is deleted, then we would return (1,1) and (1,2)
-- instead of (1,1) and (1,3) as visible.
--
-- This is because we missed advancing the datum streams for
-- non-first columns when the tuple was deleted.
--

-- partially same as Case 6 of tablesample.source
create table test_dead_values_return_@amname@(i int, j int, k int) using @amname@;
insert into test_dead_values_return_@amname@ select 1, j, j from generate_series(1, 10) j;
delete from test_dead_values_return_@amname@ where j % 2 = 0;
select * from test_dead_values_return_@amname@;
select * from gp_acquire_sample_rows('test_dead_values_return_@amname@'::regclass, 10000, 'f') as
  (totalrows pg_catalog.float8, totaldeadrows pg_catalog.float8, oversized_cols_length pg_catalog._float8, i int, j int, k int);

truncate test_dead_values_return_@amname@;

1: begin;
2: begin;

1: insert into test_dead_values_return_@amname@ select 2, j, j from generate_series(1, 10) j;
2: insert into test_dead_values_return_@amname@ select 2, j, j from generate_series(11, 20) j;

2: abort;
1: commit;

1: begin;
2: begin;

1: insert into test_dead_values_return_@amname@ select 2, j, j from generate_series(21, 30) j;
2: insert into test_dead_values_return_@amname@ select 2, j, j from generate_series(31, 40) j;
2: commit;

1: delete from test_dead_values_return_@amname@ where j % 2 = 1;
1: commit;

select * from test_dead_values_return_@amname@;
select * from gp_acquire_sample_rows('test_dead_values_return_@amname@'::regclass, 10000, 'f') as
  (totalrows pg_catalog.float8, totaldeadrows pg_catalog.float8, oversized_cols_length pg_catalog._float8, i int, j int, k int);

drop table test_dead_values_return_@amname@;
