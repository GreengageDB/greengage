-- array_agg tests
SELECT array_agg(a order by a) as a_by_a from aggtest;
    a_by_a     
---------------
 {0,42,56,100}
(1 row)

SELECT array_agg(b order by b) as b_by_b from aggtest;
           b_by_b            
-----------------------------
 {0.09561,7.8,99.097,324.78}
(1 row)

SELECT array_agg(a order by a) as a_by_a,
       array_agg(a order by b) as a_by_b,
       array_agg(b order by a) as b_by_a,
       array_agg(b order by b) as b_by_b
  FROM aggtest;
    a_by_a     |    a_by_b     |           b_by_a            |           b_by_b            
---------------+---------------+-----------------------------+-----------------------------
 {0,42,56,100} | {0,56,100,42} | {0.09561,324.78,7.8,99.097} | {0.09561,7.8,99.097,324.78}
(1 row)

-- Negative test cases for ordered aggregate syntax
SELECT count(order by a) from aggtest;       -- zero parameter aggregate
ERROR:  syntax error at or near "order"
LINE 1: SELECT count(order by a) from aggtest;
                     ^
SELECT count(a order by a) from aggtest;     -- regular (non-orderd) aggregate
 count 
-------
     4
(1 row)

SELECT abs(a order by a) from aggtest;       -- regular function
ERROR:  ORDER BY specified, but abs is not an aggregate function
LINE 1: SELECT abs(a order by a) from aggtest;
               ^
SELECT a(aggtest order by a) from aggtest;   -- function-like column reference
ERROR:  function a(aggtest) does not exist
LINE 1: SELECT a(aggtest order by a) from aggtest;
               ^
HINT:  No function matches the given name and argument types. You might need to add explicit type casts.
SELECT nosuchagg(a order by a) FROM aggtest; -- no such function
ERROR:  function nosuchagg(smallint) does not exist
LINE 1: SELECT nosuchagg(a order by a) FROM aggtest;
               ^
HINT:  No function matches the given name and argument types. You might need to add explicit type casts.
SELECT lag(a order by a) from aggtest;       -- window function (no window clause)
ERROR:  window function lag requires an OVER clause
LINE 1: SELECT lag(a order by a) from aggtest;
               ^
SELECT lag(a order by a) over (order by a) FROM aggtest;  -- window function
ERROR:  aggregate ORDER BY is not implemented for window functions
LINE 1: SELECT lag(a order by a) over (order by a) FROM aggtest;
               ^
SELECT count(a order by a) over (order by a) FROM aggtest;  -- window derived aggregate
ERROR:  aggregate ORDER BY is not implemented for window functions
LINE 1: SELECT count(a order by a) over (order by a) FROM aggtest;
               ^
SELECT array_agg(a order by a) over (order by a) FROM aggtest; -- window derived ordered aggregate
ERROR:  aggregate ORDER BY is not implemented for window functions
LINE 1: SELECT array_agg(a order by a) over (order by a) FROM aggtes...
               ^
-- agg on entryDB, this used to raise error "MIN/MAX subplan has unexpected flowtype"
SELECT min(attnum) min_attnum FROM pg_catalog.pg_attribute WHERE attrelid = 'pg_proc'::regclass AND attnum > 0;
 min_attnum 
------------
          1
(1 row)

-- check for mpp-2687
CREATE TEMPORARY TABLE mpp2687t (
    dk text,
    gk text
) DISTRIBUTED BY (dk);
CREATE VIEW mpp2687v AS
    SELECT DISTINCT gk
    FROM mpp2687t
    GROUP BY gk;
NOTICE:  view "mpp2687v" will be a temporary view
SELECT * FROM mpp2687v;
 gk 
----
(0 rows)

-- MPP-4617
select case when ten < 5 then ten else ten * 2 end, count(distinct two), count(distinct four) from tenk1 group by 1;
 case | count | count 
------+-------+-------
    3 |     1 |     2
    1 |     1 |     2
    2 |     1 |     2
    0 |     1 |     2
   16 |     1 |     2
   10 |     1 |     2
   14 |     1 |     2
   12 |     1 |     2
    4 |     1 |     2
   18 |     1 |     2
(10 rows)

select ten, ten, count(distinct two), count(distinct four) from tenk1 group by 1,2;
 ten | ten | count | count 
-----+-----+-------+-------
   3 |   3 |     1 |     2
   5 |   5 |     1 |     2
   4 |   4 |     1 |     2
   6 |   6 |     1 |     2
   1 |   1 |     1 |     2
   0 |   0 |     1 |     2
   2 |   2 |     1 |     2
   8 |   8 |     1 |     2
   9 |   9 |     1 |     2
   7 |   7 |     1 |     2
(10 rows)

--MPP-20151: distinct is transformed to a group-by
select distinct two from tenk1 order by two;
 two 
-----
   0
   1
(2 rows)

select distinct two, four from tenk1 order by two, four;
 two | four 
-----+------
   0 |    0
   0 |    2
   1 |    1
   1 |    3
(4 rows)

select distinct two, max(two) over() from tenk1 order by two;
 two | max 
-----+-----
   0 |   1
   1 |   1
(2 rows)

select distinct two, sum(four) over() from tenk1 order by two;
 two |  sum  
-----+-------
   0 | 15000
   1 | 15000
(2 rows)

select distinct two, sum(four) from tenk1 group by two order by two;
 two |  sum  
-----+-------
   0 |  5000
   1 | 10000
(2 rows)

select distinct two, sum(four) from tenk1 group by two having sum(four) > 5000;
 two |  sum  
-----+-------
   1 | 10000
(1 row)

select distinct t1.two, t2.two, t1.four, t2.four from tenk1 t1, tenk1 t2 where t1.hundred=t2.hundred order by t1.two, t1.four;
 two | two | four | four 
-----+-----+------+------
   0 |   0 |    0 |    0
   0 |   0 |    2 |    2
   1 |   1 |    1 |    1
   1 |   1 |    3 |    3
(4 rows)

-- A variant with more result rows. We had a bug at one point where the
-- Motion Gather node on top of this was missing the Merge Key, and hence
-- the output came out unsorted. But it was not visible if all the rows
-- were processed on the same segment, as is the case with the above variant
-- with only two distinct 'two' values.
select distinct ten, sum(ten) over() from tenk1 order by ten;
 ten |  sum  
-----+-------
   0 | 45000
   1 | 45000
   2 | 45000
   3 | 45000
   4 | 45000
   5 | 45000
   6 | 45000
   7 | 45000
   8 | 45000
   9 | 45000
(10 rows)

-- Test for a planner bug we used to have, when this query gets planned
-- as a merge join. This should perform a merge join between 'l' and 'ps',
-- using both pk and sk as the merge keys. Due to the bug, the planner
-- used mix up the columns in the path keys, and used incorrect columns
-- as the merge keys. (This is a modified version of a TPC-H query)
create table l (ok bigint, pk integer, sk integer, quantity numeric) distributed by (ok);
create table ps (pk integer, sk integer, availqty integer) distributed by (pk);
insert into l select g%5, 50-g, g, 5 from generate_series(1, 50) g;
insert into ps select g, 50-g, 10 from generate_series(1, 25) g;
select  g.pk, g.sk, ps.availqty
from ps,
     (select sum(l.quantity) as qty_sum, l.pk, l.sk
      from l
      group by l.pk, l.sk ) g
where g.pk = ps.pk and g.sk = ps.sk
and ps.availqty > g.qty_sum ;
 pk | sk | availqty 
----+----+----------
  6 | 44 |       10
  3 | 47 |       10
 21 | 29 |       10
 15 | 35 |       10
 20 | 30 |       10
 25 | 25 |       10
 13 | 37 |       10
 22 | 28 |       10
  7 | 43 |       10
 16 | 34 |       10
 24 | 26 |       10
 10 | 40 |       10
 19 | 31 |       10
  8 | 42 |       10
  9 | 41 |       10
  4 | 46 |       10
 14 | 36 |       10
  5 | 45 |       10
 11 | 39 |       10
 18 | 32 |       10
 12 | 38 |       10
  2 | 48 |       10
 23 | 27 |       10
  1 | 49 |       10
 17 | 33 |       10
(25 rows)

-- the same, but force a merge join and sorted agg.
set enable_hashagg=off;
set enable_hashjoin=off;
set enable_mergejoin=on;
select  g.pk, g.sk, ps.availqty
from ps,
     (select sum(l.quantity) as qty_sum, l.pk, l.sk
      from l
      group by l.pk, l.sk ) g
where g.pk = ps.pk and g.sk = ps.sk
and ps.availqty > g.qty_sum ;
 pk | sk | availqty 
----+----+----------
  1 | 49 |       10
  2 | 48 |       10
  3 | 47 |       10
  4 | 46 |       10
  5 | 45 |       10
  6 | 44 |       10
  7 | 43 |       10
  8 | 42 |       10
  9 | 41 |       10
 10 | 40 |       10
 11 | 39 |       10
 12 | 38 |       10
 13 | 37 |       10
 14 | 36 |       10
 15 | 35 |       10
 16 | 34 |       10
 17 | 33 |       10
 18 | 32 |       10
 19 | 31 |       10
 20 | 30 |       10
 21 | 29 |       10
 22 | 28 |       10
 23 | 27 |       10
 24 | 26 |       10
 25 | 25 |       10
(25 rows)

reset enable_hashagg;
reset enable_hashjoin;
reset enable_mergejoin;
drop table l, ps;
-- Test having a SRF in the targetlist, with an aggregate. GPDB used to not
-- handle this, because the SRF-in-targetlist support was removed from Agg
-- node, as an optimization. It's been put back since, so this works now.
--
-- We have this same test in the upstream 'aggregates' test, but with MAX().
-- That's picked up by the MIN/MAX optimization, and turned into an
-- LIMIT 1 query, however, and doesn't exercise from the SRF-in-targetlist
-- support.
select avg(unique2), generate_series(1,3) as g from tenk1 order by g desc;
          avg          | g 
-----------------------+---
 4999.5000000000000000 | 3
 4999.5000000000000000 | 2
 4999.5000000000000000 | 1
(3 rows)

--
-- "PREFUNC" is accepted as an alias for "COMBINEFUNC", for compatibility with
-- GPDB 5 and below.
--
create function int8pl_with_notice(int8, int8) returns int8
AS $$
begin
  raise notice 'combinefunc called';
  return $1 + $2;
end;
$$ language plpgsql strict;
create aggregate mysum_prefunc(int4) (
  sfunc = int4_sum,
  stype=bigint,
  prefunc=int8pl_with_notice
);
set optimizer_force_multistage_agg = on;
select mysum_prefunc(a::int4) from aggtest;
NOTICE:  combinefunc called
NOTICE:  combinefunc called
 mysum_prefunc 
---------------
           198
(1 row)

reset optimizer_force_multistage_agg;
-- Test an aggregate with 'internal' transition type, and a combine function,
-- but no serial/deserial functions. This is valid, but we have no use for
-- the combine function in GPDB in that case.
CREATE AGGREGATE my_numeric_avg(numeric) (
  stype = internal,
  sfunc = numeric_avg_accum,
  finalfunc = numeric_avg,
  combinefunc = numeric_avg_combine
);
create temp table numerictesttab as select g::numeric as n from generate_series(1,10) g;
NOTICE:  Table doesn't have 'DISTRIBUTED BY' clause -- Using column(s) named 'n' as the Greenplum Database data distribution key for this table.
HINT:  The 'DISTRIBUTED BY' clause determines the distribution of data. Make sure column(s) chosen are the optimal data distribution key to minimize skew.
select my_numeric_avg(n) from numerictesttab;
   my_numeric_avg   
--------------------
 5.5000000000000000
(1 row)

--- Test distinct on UDF which EXECUTE ON ALL SEGMENTS
CREATE FUNCTION distinct_test() RETURNS SETOF boolean EXECUTE ON ALL SEGMENTS
    LANGUAGE plpgsql AS $$
BEGIN
    RETURN QUERY SELECT true;
END
$$;
SELECT DISTINCT distinct_test();
 distinct_test 
---------------
 t
(1 row)

DROP FUNCTION distinct_test();
-- Test multi-phase aggregate with subquery scan
create table multiagg_with_subquery (i int, j int, k int, m int) distributed by (i);
insert into multiagg_with_subquery select i, i+1, i+2, i+3 from generate_series(1, 10)i;
explain (costs off)
select count(distinct j), count(distinct k), count(distinct m) from (select j,k,m from multiagg_with_subquery group by j,k,m ) sub group by j;
                                                                         QUERY PLAN                                                                          
-------------------------------------------------------------------------------------------------------------------------------------------------------------
 Gather Motion 3:1  (slice5; segments: 3)
   ->  Hash Join
         Hash Cond: (NOT (share0_ref3.j IS DISTINCT FROM share0_ref1.j))
         ->  Hash Join
               Hash Cond: (NOT (share0_ref3.j IS DISTINCT FROM share0_ref2.j))
               ->  HashAggregate
                     Group Key: share0_ref3.j
                     ->  HashAggregate
                           Group Key: share0_ref3.j, share0_ref3.j
                           ->  Redistribute Motion 3:3  (slice1; segments: 3)
                                 Hash Key: share0_ref3.j
                                 ->  HashAggregate
                                       Group Key: share0_ref3.j, share0_ref3.j
                                       ->  Shared Scan (share slice:id 1:0)
               ->  Hash
                     ->  HashAggregate
                           Group Key: share0_ref2.j
                           ->  HashAggregate
                                 Group Key: share0_ref2.j, share0_ref2.k
                                 ->  Redistribute Motion 3:3  (slice2; segments: 3)
                                       Hash Key: share0_ref2.j
                                       ->  HashAggregate
                                             Group Key: share0_ref2.j, share0_ref2.k
                                             ->  Shared Scan (share slice:id 2:0)
         ->  Hash
               ->  HashAggregate
                     Group Key: share0_ref1.j
                     ->  HashAggregate
                           Group Key: share0_ref1.j, share0_ref1.m
                           ->  Redistribute Motion 3:3  (slice4; segments: 3)
                                 Hash Key: share0_ref1.j
                                 ->  HashAggregate
                                       Group Key: share0_ref1.j, share0_ref1.m
                                       ->  Shared Scan (share slice:id 4:0)
                                             ->  Materialize
                                                   ->  HashAggregate
                                                         Group Key: multiagg_with_subquery.j, multiagg_with_subquery.k, multiagg_with_subquery.m
                                                         ->  Redistribute Motion 3:3  (slice3; segments: 3)
                                                               Hash Key: multiagg_with_subquery.j, multiagg_with_subquery.k, multiagg_with_subquery.m
                                                               ->  HashAggregate
                                                                     Group Key: multiagg_with_subquery.j, multiagg_with_subquery.k, multiagg_with_subquery.m
                                                                     ->  Seq Scan on multiagg_with_subquery
 Optimizer: Postgres query optimizer
(43 rows)

select count(distinct j), count(distinct k), count(distinct m) from (select j,k,m from multiagg_with_subquery group by j,k,m ) sub group by j;
 count | count | count 
-------+-------+-------
     1 |     1 |     1
     1 |     1 |     1
     1 |     1 |     1
     1 |     1 |     1
     1 |     1 |     1
     1 |     1 |     1
     1 |     1 |     1
     1 |     1 |     1
     1 |     1 |     1
     1 |     1 |     1
(10 rows)

drop table multiagg_with_subquery;
-- Test multi-phase aggregate with an expression as the group key
create table multiagg_expr_group_tbl (i int, j int) distributed by (i);
insert into multiagg_expr_group_tbl values(-1, -2), (-1, -1), (0, 1), (1, 2);
explain (costs off) select j >= 0, not j >= 0 from multiagg_expr_group_tbl group by 1;
                           QUERY PLAN                            
-----------------------------------------------------------------
 Gather Motion 3:1  (slice2; segments: 3)
   ->  HashAggregate
         Group Key: ((multiagg_expr_group_tbl.j >= 0))
         ->  Redistribute Motion 3:3  (slice1; segments: 3)
               Hash Key: ((multiagg_expr_group_tbl.j >= 0))
               ->  HashAggregate
                     Group Key: (multiagg_expr_group_tbl.j >= 0)
                     ->  Seq Scan on multiagg_expr_group_tbl
 Optimizer: Postgres query optimizer
(9 rows)

select j >= 0, not j >= 0 from multiagg_expr_group_tbl group by 1;
 ?column? | ?column? 
----------+----------
 t        | f
 f        | t
(2 rows)

select j >= 0,
		case when not j >= 0 then
			'not greater than 0'
		end
		from multiagg_expr_group_tbl group by 1;
 ?column? |        case        
----------+--------------------
 t        | 
 f        | not greater than 0
(2 rows)

drop table multiagg_expr_group_tbl;
CREATE TABLE multiagg_expr_group_tbl2 (
	A int,
	B int,
	C text ) DISTRIBUTED RANDOMLY;
CREATE VIEW multiagg_expr_group_view as select B, rtrim(C) AS C FROM multiagg_expr_group_tbl2;
INSERT INTO multiagg_expr_group_tbl2 VALUES(1,1,1), (2,2,2);
SELECT v1.B
  FROM multiagg_expr_group_view v1
  GROUP BY
  v1.B, v1.C
  HAVING ( v1.B= ( SELECT v2.B FROM multiagg_expr_group_view v2 WHERE v1.C = v2.C));
 b 
---
 1
 2
(2 rows)

-- Test 3 stage aggregate with an expression contains subplan as the group key
create table agg_a (id int, a int, b int, c numeric(10, 0));
NOTICE:  Table doesn't have 'DISTRIBUTED BY' clause -- Using column named 'id' as the Greenplum Database data distribution key for this table.
HINT:  The 'DISTRIBUTED BY' clause determines the distribution of data. Make sure column(s) chosen are the optimal data distribution key to minimize skew.
create table agg_b (id int, a int, b int, c int);
NOTICE:  Table doesn't have 'DISTRIBUTED BY' clause -- Using column named 'id' as the Greenplum Database data distribution key for this table.
HINT:  The 'DISTRIBUTED BY' clause determines the distribution of data. Make sure column(s) chosen are the optimal data distribution key to minimize skew.
insert into agg_a values (1, 1, 1, 100);
insert into agg_b values (1, 1, 1, 1);
-- The below issue is planner only.
-- The subplan in the group key expression and the type cast "bb.v::text" under select
-- will cause the vars(b.a, b.b) showed in the expression appear in first agg's target list.
-- And grps_tlist for MppGroupContext will contains these vars with the group expression,
-- but normal case only contains group expression in grps_tlist.
-- We used to sure that there could only be one target entry(the expression here) in grps_tlist
-- for a group, but current case also contains b.a and b.b.
-- When we build the 3 stage agg and try to split the Aggref and find or add target list into
-- different Aggref stages with function `split_aggref`, it'll match to wrong Vars in
-- `AGGSTAGE_INTERMEDIATE` and `AGGSTAGE_FINAL` stage.
-- For the below query, it used to do the avg on b.b for the `AGGSTAGE_INTERMEDIATE` and
-- `AGGSTAGE_FINAL` stage and cause a crash since the type expected here should be numeric, but
-- get a int value when executing numeric_avg_deserialize.
set enable_groupagg = false;
set optimizer = off; -- the case is planner only, so disable orca
explain (costs off, verbose)
SELECT bb.v::text, count(distinct a.a), avg(a.c)	-- note the type cast
FROM agg_a a
Join ( SELECT b.b,
			(CASE WHEN b.a >= (SELECT b.b - 2)		-- note the subplan here
				THEN b.a ELSE b.b END) as v
		FROM agg_b b) as bb
ON a.a = bb.b
GROUP BY bb.v;
                                                                                           QUERY PLAN                                                                                           
------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Gather Motion 3:1  (slice4; segments: 3)
   Output: ((CASE WHEN (b.a >= (SubPlan 1)) THEN b.a ELSE b.b END)::text), (count(a.a)), (pg_catalog.avg((pg_catalog.avg((avg(a.c)))))), (CASE WHEN (b.a >= (SubPlan 2)) THEN b.a ELSE b.b END)
   ->  HashAggregate
         Output: (CASE WHEN (b.a >= (SubPlan 1)) THEN b.a ELSE b.b END)::text, count(a.a), pg_catalog.avg((pg_catalog.avg((avg(a.c))))), (CASE WHEN (b.a >= (SubPlan 2)) THEN b.a ELSE b.b END)
         Group Key: (CASE WHEN (b.a >= (SubPlan 2)) THEN b.a ELSE b.b END)
         ->  HashAggregate
               Output: (CASE WHEN (b.a >= (SubPlan 2)) THEN b.a ELSE b.b END), b.a, b.b, a.a, pg_catalog.avg((avg(a.c)))
               Group Key: (CASE WHEN (b.a >= (SubPlan 2)) THEN b.a ELSE b.b END), b.a
               ->  Redistribute Motion 3:3  (slice3; segments: 3)
                     Output: (CASE WHEN (b.a >= (SubPlan 2)) THEN b.a ELSE b.b END), b.a, b.b, a.a, (avg(a.c))
                     Hash Key: (CASE WHEN (b.a >= (SubPlan 2)) THEN b.a ELSE b.b END)
                     ->  HashAggregate
                           Output: (CASE WHEN (b.a >= (SubPlan 2)) THEN b.a ELSE b.b END), b.a, b.b, a.a, avg(a.c)
                           Group Key: CASE WHEN (b.a >= (SubPlan 2)) THEN b.a ELSE b.b END, a.a
                           ->  Hash Join
                                 Output: b.a, b.b, a.a, a.c, CASE WHEN (b.a >= (SubPlan 2)) THEN b.a ELSE b.b END
                                 Hash Cond: (a.a = b.b)
                                 ->  Redistribute Motion 3:3  (slice1; segments: 3)
                                       Output: a.a, a.c, a.id
                                       Hash Key: a.a
                                       ->  Seq Scan on public.agg_a a
                                             Output: a.a, a.c, a.id
                                 ->  Hash
                                       Output: b.a, b.b, b.id
                                       ->  Redistribute Motion 3:3  (slice2; segments: 3)
                                             Output: b.a, b.b, b.id
                                             Hash Key: b.b
                                             ->  Seq Scan on public.agg_b b
                                                   Output: b.a, b.b, b.id
                                 SubPlan 2  (slice3; segments: 1)
                                   ->  Result
                                         Output: (b.b - 2)
         SubPlan 1  (slice4; segments: 1)
           ->  Result
                 Output: (b.b - 2)
 Optimizer: Postgres query optimizer
 Settings: enable_groupagg=off
(37 rows)

SELECT bb.v::text, count(distinct a.a), avg(a.c)	-- note the type cast
FROM agg_a a
Join ( SELECT b.b,
			(CASE WHEN b.a >= (SELECT b.b - 2)		-- note the subplan here
				THEN b.a ELSE b.b END) as v
		FROM agg_b b) as bb
ON a.a = bb.b
GROUP BY bb.v;
 v | count |         avg          
---+-------+----------------------
 1 |     1 | 100.0000000000000000
(1 row)

-- with multi dqa
explain (costs off, verbose)
SELECT bb.v::text, count(distinct a.a), count(distinct a.b), avg(a.c)	-- note the type cast
FROM agg_a a
Join ( SELECT b.b,
			(CASE WHEN b.a >= (SELECT b.b - 2)		-- note the subplan here
				THEN b.a ELSE b.b END) as v
		FROM agg_b b) as bb
ON a.a = bb.b
GROUP BY bb.v;
                                                                                                                 QUERY PLAN                                                                                                                  
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Gather Motion 3:1  (slice5; segments: 3)
   Output: ((CASE WHEN (share0_ref2.a >= (SubPlan 1)) THEN share0_ref2.a ELSE share0_ref2.b END)::text), (count(share0_ref2.a_1)), (count(share0_ref1.b_1)), (pg_catalog.avg((pg_catalog.avg((avg(share0_ref2.c)))))), share0_ref2.col_6
   ->  Hash Join
         Output: (CASE WHEN (share0_ref2.a >= (SubPlan 1)) THEN share0_ref2.a ELSE share0_ref2.b END)::text, (count(share0_ref2.a_1)), (count(share0_ref1.b_1)), (pg_catalog.avg((pg_catalog.avg((avg(share0_ref2.c)))))), share0_ref2.col_6
         Hash Cond: (NOT (share0_ref2.col_6 IS DISTINCT FROM share0_ref1.col_6))
         ->  HashAggregate
               Output: share0_ref2.col_6, share0_ref2.a, share0_ref2.b, count(share0_ref2.a_1), pg_catalog.avg((pg_catalog.avg((avg(share0_ref2.c)))))
               Group Key: share0_ref2.col_6
               ->  HashAggregate
                     Output: share0_ref2.col_6, share0_ref2.a, share0_ref2.b, share0_ref2.a_1, pg_catalog.avg((avg(share0_ref2.c)))
                     Group Key: share0_ref2.col_6, share0_ref2.a
                     ->  Redistribute Motion 3:3  (slice1; segments: 3)
                           Output: share0_ref2.col_6, share0_ref2.a, share0_ref2.b, share0_ref2.a_1, (avg(share0_ref2.c))
                           Hash Key: share0_ref2.col_6
                           ->  HashAggregate
                                 Output: share0_ref2.col_6, share0_ref2.a, share0_ref2.b, share0_ref2.a_1, avg(share0_ref2.c)
                                 Group Key: share0_ref2.col_6, share0_ref2.a_1
                                 ->  Shared Scan (share slice:id 1:0)
                                       Output: share0_ref2.a, share0_ref2.b, share0_ref2.a_1, share0_ref2.b_1, share0_ref2.c, share0_ref2.col_6
         ->  Hash
               Output: share0_ref1.col_6, share0_ref1.a, share0_ref1.b, (count(share0_ref1.b_1))
               ->  HashAggregate
                     Output: share0_ref1.col_6, share0_ref1.a, share0_ref1.b, count(share0_ref1.b_1)
                     Group Key: share0_ref1.col_6
                     ->  HashAggregate
                           Output: share0_ref1.col_6, share0_ref1.a, share0_ref1.b, share0_ref1.b_1
                           Group Key: share0_ref1.col_6, share0_ref1.a
                           ->  Redistribute Motion 3:3  (slice4; segments: 3)
                                 Output: share0_ref1.col_6, share0_ref1.a, share0_ref1.b, share0_ref1.b_1
                                 Hash Key: share0_ref1.col_6
                                 ->  HashAggregate
                                       Output: share0_ref1.col_6, share0_ref1.a, share0_ref1.b, share0_ref1.b_1
                                       Group Key: share0_ref1.col_6, share0_ref1.b_1
                                       ->  Shared Scan (share slice:id 4:0)
                                             Output: share0_ref1.a, share0_ref1.b, share0_ref1.a_1, share0_ref1.b_1, share0_ref1.c, share0_ref1.col_6
                                             ->  Materialize
                                                   Output: b.a, b.b, a.a, a.b, a.c, (CASE WHEN (b.a >= (SubPlan 2)) THEN b.a ELSE b.b END)
                                                   ->  Hash Join
                                                         Output: b.a, b.b, a.a, a.b, a.c, CASE WHEN (b.a >= (SubPlan 2)) THEN b.a ELSE b.b END
                                                         Hash Cond: (a.a = b.b)
                                                         ->  Redistribute Motion 3:3  (slice2; segments: 3)
                                                               Output: a.a, a.b, a.c, a.id
                                                               Hash Key: a.a
                                                               ->  Seq Scan on public.agg_a a
                                                                     Output: a.a, a.b, a.c, a.id
                                                         ->  Hash
                                                               Output: b.a, b.b, b.id
                                                               ->  Redistribute Motion 3:3  (slice3; segments: 3)
                                                                     Output: b.a, b.b, b.id
                                                                     Hash Key: b.b
                                                                     ->  Seq Scan on public.agg_b b
                                                                           Output: b.a, b.b, b.id
                                                         SubPlan 2  (slice4; segments: 1)
                                                           ->  Result
                                                                 Output: (b.b - 2)
         SubPlan 1  (slice5; segments: 1)
           ->  Result
                 Output: (share0_ref2.b - 2)
 Optimizer: Postgres query optimizer
 Settings: enable_groupagg=off
(60 rows)

SELECT bb.v::text, count(distinct a.a), count(distinct a.b), avg(a.c)	-- note the type cast
FROM agg_a a
Join ( SELECT b.b,
			(CASE WHEN b.a >= (SELECT b.b - 2)		-- note the subplan here
				THEN b.a ELSE b.b END) as v
		FROM agg_b b) as bb
ON a.a = bb.b
GROUP BY bb.v;
 v | count | count |         avg          
---+-------+-------+----------------------
 1 |     1 |     1 | 100.0000000000000000
(1 row)

reset optimizer;
reset enable_groupagg;
-- test multi DQA with guc gp_enable_mdqa_shared_scan
set optimizer = off; -- the case is planner only, so disable orca
set gp_enable_mdqa_shared_scan = true;
explain select sum(distinct a), sum(distinct b), c from agg_a group by c;
                                                   QUERY PLAN                                                    
-----------------------------------------------------------------------------------------------------------------
 Gather Motion 3:1  (slice3; segments: 3)  (cost=2.59..2.64 rows=1 width=48)
   ->  Hash Join  (cost=2.59..2.64 rows=1 width=48)
         Hash Cond: (NOT (share0_ref2.c IS DISTINCT FROM share0_ref1.c))
         ->  HashAggregate  (cost=1.29..1.30 rows=1 width=24)
               Group Key: share0_ref2.c
               ->  HashAggregate  (cost=1.27..1.28 rows=1 width=20)
                     Group Key: share0_ref2.c, share0_ref2.a
                     ->  Redistribute Motion 3:3  (slice1; segments: 3)  (cost=1.23..1.25 rows=1 width=20)
                           Hash Key: share0_ref2.c
                           ->  HashAggregate  (cost=1.23..1.23 rows=1 width=20)
                                 Group Key: share0_ref2.c, share0_ref2.a
                                 ->  Shared Scan (share slice:id 1:0)  (cost=1.01..1.22 rows=1 width=13)
         ->  Hash  (cost=1.31..1.31 rows=1 width=24)
               ->  HashAggregate  (cost=1.29..1.30 rows=1 width=24)
                     Group Key: share0_ref1.c
                     ->  HashAggregate  (cost=1.27..1.28 rows=1 width=20)
                           Group Key: share0_ref1.c, share0_ref1.b
                           ->  Redistribute Motion 3:3  (slice2; segments: 3)  (cost=1.23..1.25 rows=1 width=20)
                                 Hash Key: share0_ref1.c
                                 ->  HashAggregate  (cost=1.23..1.23 rows=1 width=20)
                                       Group Key: share0_ref1.c, share0_ref1.b
                                       ->  Shared Scan (share slice:id 2:0)  (cost=1.01..1.22 rows=1 width=13)
                                             ->  Materialize  (cost=0.00..1.01 rows=1 width=13)
                                                   ->  Seq Scan on agg_a  (cost=0.00..1.01 rows=1 width=13)
 Optimizer: Postgres query optimizer
(25 rows)

select sum(distinct a), sum(distinct b), c from agg_a group by c;
 sum | sum |  c  
-----+-----+-----
   1 |   1 | 100
(1 row)

set gp_enable_mdqa_shared_scan = false;
explain select sum(distinct a), sum(distinct b), c from agg_a group by c;
                                                   QUERY PLAN                                                    
-----------------------------------------------------------------------------------------------------------------
 Gather Motion 3:1  (slice3; segments: 3)  (cost=2.17..2.22 rows=1 width=48)
   ->  Hash Join  (cost=2.17..2.22 rows=1 width=48)
         Hash Cond: (NOT (agg_a.c IS DISTINCT FROM agg_a_1.c))
         ->  HashAggregate  (cost=1.09..1.10 rows=1 width=24)
               Group Key: agg_a.c
               ->  HashAggregate  (cost=1.06..1.07 rows=1 width=20)
                     Group Key: agg_a.c, agg_a.a
                     ->  Redistribute Motion 3:3  (slice1; segments: 3)  (cost=1.02..1.04 rows=1 width=20)
                           Hash Key: agg_a.c
                           ->  HashAggregate  (cost=1.02..1.02 rows=1 width=20)
                                 Group Key: agg_a.c, agg_a.a
                                 ->  Seq Scan on agg_a  (cost=0.00..1.01 rows=1 width=13)
         ->  Hash  (cost=1.11..1.11 rows=1 width=24)
               ->  HashAggregate  (cost=1.09..1.10 rows=1 width=24)
                     Group Key: agg_a_1.c
                     ->  HashAggregate  (cost=1.06..1.07 rows=1 width=20)
                           Group Key: agg_a_1.c, agg_a_1.b
                           ->  Redistribute Motion 3:3  (slice2; segments: 3)  (cost=1.02..1.04 rows=1 width=20)
                                 Hash Key: agg_a_1.c
                                 ->  HashAggregate  (cost=1.02..1.02 rows=1 width=20)
                                       Group Key: agg_a_1.c, agg_a_1.b
                                       ->  Seq Scan on agg_a agg_a_1  (cost=0.00..1.01 rows=1 width=13)
 Optimizer: Postgres query optimizer
(23 rows)

select sum(distinct a), sum(distinct b), c from agg_a group by c;
 sum | sum |  c  
-----+-----+-----
   1 |   1 | 100
(1 row)

reset optimizer;
reset gp_enable_mdqa_shared_scan;
