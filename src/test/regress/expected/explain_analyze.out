-- start_matchsubs
-- m/ Gather Motion [12]:1  \(slice1; segments: [12]\)/
-- s/ Gather Motion [12]:1  \(slice1; segments: [12]\)/ Gather Motion XXX/
-- m/Memory Usage: \d+\w?B/
-- s/Memory Usage: \d+\w?B/Memory Usage: ###B/
-- m/Buckets: \d+/
-- s/Buckets: \d+/Buckets: ###/
-- m/Batches: \d+/
-- s/Batches: \d+/Batches: ###/
-- m/Planning Time: [0-9.]+ ms/
-- s/Planning Time: [0-9.]+ ms/Planning Time: #.### ms/
-- m/Execution Time: [0-9.]+ ms/
-- s/Execution Time: [0-9.]+ ms/Execution Time: #.### ms/
-- m/Executor memory: \d+\w? bytes/
-- s/Executor memory: \d+\w? bytes/Executor memory: ### bytes/
-- m/Memory used:\s+\d+\w?B/
-- s/Memory used:\s+\d+\w?B/Memory used:  ###B/
-- m/\d+\w? bytes max \(seg\d+\)/
-- s/\d+\w? bytes max \(seg\d+\)/### bytes max (seg#)/
-- m/Work_mem: \d+\w? bytes max/
-- s/Work_mem: \d+\w? bytes max/Work_mem: ### bytes max/
-- end_matchsubs
CREATE TEMP TABLE empty_table(a int);
NOTICE:  Table doesn't have 'DISTRIBUTED BY' clause -- Using column named 'a' as the Greenplum Database data distribution key for this table.
HINT:  The 'DISTRIBUTED BY' clause determines the distribution of data. Make sure column(s) chosen are the optimal data distribution key to minimize skew.
-- We used to incorrectly report "never executed" for a node that returns 0 rows
-- from every segment. This was misleading because "never executed" should
-- indicate that the node was never executed by its parent.
-- explain_processing_off
EXPLAIN (ANALYZE, TIMING OFF, COSTS OFF, SUMMARY OFF) SELECT a FROM empty_table;
                            QUERY PLAN                            
------------------------------------------------------------------
 Gather Motion 3:1  (slice1; segments: 3) (actual rows=0 loops=1)
   ->  Seq Scan on empty_table (actual rows=0 loops=1)
 Optimizer: Postgres query optimizer
(3 rows)

-- explain_processing_on
-- For a node that is truly never executed, we still expect "never executed" to
-- be reported
-- explain_processing_off
EXPLAIN (ANALYZE, TIMING OFF, COSTS OFF, SUMMARY OFF) SELECT t1.a FROM empty_table t1 join empty_table t2 on t1.a = t2.a;
                            QUERY PLAN                            
------------------------------------------------------------------
 Gather Motion 3:1  (slice1; segments: 3) (actual rows=0 loops=1)
   ->  Hash Join (actual rows=0 loops=1)
         Hash Cond: (t1.a = t2.a)
         ->  Seq Scan on empty_table t1 (actual rows=0 loops=1)
         ->  Hash (never executed)
               ->  Seq Scan on empty_table t2 (never executed)
 Optimizer: Postgres query optimizer
(7 rows)

-- explain_processing_on
-- If all QEs hit errors when executing sort, we might not receive stat data for sort.
-- rethrow error before print explain info.
create extension if not exists gp_inject_fault;
create table sort_error_test1(tc1 int, tc2 int);
NOTICE:  Table doesn't have 'DISTRIBUTED BY' clause -- Using column named 'tc1' as the Greenplum Database data distribution key for this table.
HINT:  The 'DISTRIBUTED BY' clause determines the distribution of data. Make sure column(s) chosen are the optimal data distribution key to minimize skew.
create table sort_error_test2(tc1 int, tc2 int);
NOTICE:  Table doesn't have 'DISTRIBUTED BY' clause -- Using column named 'tc1' as the Greenplum Database data distribution key for this table.
HINT:  The 'DISTRIBUTED BY' clause determines the distribution of data. Make sure column(s) chosen are the optimal data distribution key to minimize skew.
insert into sort_error_test1 select i,i from generate_series(1,20) i;
select gp_inject_fault('explain_analyze_sort_error', 'error', dbid)
    from gp_segment_configuration where role = 'p' and content > -1;
 gp_inject_fault 
-----------------
 Success:
 Success:
 Success:
(3 rows)

EXPLAIN analyze insert into sort_error_test2 select * from sort_error_test1 order by 1;
ERROR:  fault triggered, fault name:'explain_analyze_sort_error' fault type:'error'  (seg1 127.0.1.1:7003 pid=103595)
select count(*) from sort_error_test2;
 count 
-------
     0
(1 row)

select gp_inject_fault('explain_analyze_sort_error', 'reset', dbid)
    from gp_segment_configuration where role = 'p' and content > -1;
 gp_inject_fault 
-----------------
 Success:
 Success:
 Success:
(3 rows)

drop table sort_error_test1;
drop table sort_error_test2;
--
-- Test correct slice stats reporting in case of duplicated subplans
--
create table slice_test(i int, j int) distributed by (i);
create table slice_test2(i int, j int) distributed by (i);
insert into slice_test select i, i from generate_series(0, 100) i;
insert into slice_test select i, 2*i from generate_series(0, 100) i;
insert into slice_test2 values (0, 1);
-- explain_processing_off
-- create duplicate subplan in QE slice
explain (analyze, timing off, costs off) select a.i from slice_test a
  where a.j = (select b.i from slice_test2 b where a.i = 0 or b.i = 0)
    and a.i = a.j;
                                                QUERY PLAN                                                 
-----------------------------------------------------------------------------------------------------------
 Gather Motion 3:1  (slice1; segments: 3) (actual rows=2 loops=1)
   ->  Seq Scan on slice_test a (actual rows=2 loops=1)
         Filter: ((j = (SubPlan 1)) AND ((SubPlan 1) = i))
         Rows Removed by Filter: 74
         SubPlan 1
           ->  Result (actual rows=1 loops=78)
                 Filter: ((a.i = 0) OR (b.i = 0))
                 ->  Materialize (actual rows=1 loops=80)
                       ->  Broadcast Motion 3:3  (slice2; segments: 3) (actual rows=1 loops=1)
                             ->  Seq Scan on slice_test2 b (actual rows=1 loops=1)
 Optimizer: Postgres-based planner
 Planning Time: 0.662 ms
   (slice0)    Executor memory: 47K bytes.
   (slice1)    Executor memory: 43K bytes avg x 3 workers, 43K bytes max (seg0).  Work_mem: 17K bytes max.
   (slice2)    Executor memory: 37K bytes avg x 3 workers, 37K bytes max (seg0).
 Memory used:  128000kB
 Execution Time: 4.953 ms
(17 rows)

-- checking this didn't break previous behavior
-- create multiple initplans in slice 0 (should be printed as two slices)
explain (analyze, timing off, costs off)
  select a.i from (select x::int as i, x::int / 5 as j from round(random() / 5) as x) a
    where a.j = (select round(random() / 5)::int where a.i = 0)
      and a.i = a.j;
                                   QUERY PLAN                                    
---------------------------------------------------------------------------------
 Function Scan on round x (actual rows=1 loops=1)
   Filter: (((SubPlan 1) = (x)::integer) AND (((x)::integer / 5) = (SubPlan 1)))
   InitPlan 2 (returns $1)
     ->  Result (actual rows=1 loops=1)
   SubPlan 1
     ->  Result (actual rows=1 loops=2)
           One-Time Filter: ((x.x)::integer = 0)
 Optimizer: Postgres-based planner
 Planning Time: 0.245 ms
   (slice0)    Executor memory: 19K bytes.
   (slice1)    Executor memory: 36K bytes.  Work_mem: 17K bytes max.
 Memory used:  128000kB
 Execution Time: 0.082 ms
(14 rows)

-- explain_processing_on
drop table slice_test;
drop table slice_test2;
