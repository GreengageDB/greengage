--
-- Queries that lead to hanging (not dead lock) when we don't handle synchronization properly in shared scan
-- Queries that lead to wrong result when we don't finish executing the subtree below the shared scan being squelched.
--
-- start_ignore
CREATE EXTENSION IF NOT EXISTS gp_inject_fault;
-- end_ignore
CREATE SCHEMA shared_scan;
SET search_path = shared_scan;
CREATE TABLE foo (a int, b int);
NOTICE:  Table doesn't have 'DISTRIBUTED BY' clause -- Using column named 'a' as the Greenplum Database data distribution key for this table.
HINT:  The 'DISTRIBUTED BY' clause determines the distribution of data. Make sure column(s) chosen are the optimal data distribution key to minimize skew.
CREATE TABLE bar (c int, d int);
NOTICE:  Table doesn't have 'DISTRIBUTED BY' clause -- Using column named 'c' as the Greenplum Database data distribution key for this table.
HINT:  The 'DISTRIBUTED BY' clause determines the distribution of data. Make sure column(s) chosen are the optimal data distribution key to minimize skew.
CREATE TABLE jazz(e int, f int);
NOTICE:  Table doesn't have 'DISTRIBUTED BY' clause -- Using column named 'e' as the Greenplum Database data distribution key for this table.
HINT:  The 'DISTRIBUTED BY' clause determines the distribution of data. Make sure column(s) chosen are the optimal data distribution key to minimize skew.
INSERT INTO foo values (1, 2);
INSERT INTO bar SELECT i, i from generate_series(1, 100)i;
INSERT INTO jazz VALUES (2, 2), (3, 3);
ANALYZE foo;
ANALYZE bar;
ANALYZE jazz;
SELECT $query$
SELECT * FROM
        (
        WITH cte AS (SELECT * FROM foo)
        SELECT * FROM (SELECT * FROM cte UNION ALL SELECT * FROM cte)
        AS X
        JOIN bar ON b = c
        ) AS XY
        JOIN jazz on c = e AND b = f;
$query$ AS qry \gset
-- We are very particular about this plan shape and data distribution with ORCA:
-- 1. `jazz` has to be the inner table of the outer HASH JOIN, so that on a
-- segment which has zero tuples in `jazz`, the Sequence node that contains the
-- Shared Scan will be squelched on that segment. If `jazz` is not on the inner
-- side, the above mentioned "hang" scenario will not be covered.
-- 2. The Shared Scan producer has to be on a different slice from consumers,
-- and some tuples coming out of the Share Scan producer on one segments are
-- redistributed to a different segment over Motion. If not, the above mentioned
-- "wrong result" scenario will not be covered.
EXPLAIN (COSTS OFF)
:qry ;
                                  QUERY PLAN                                  
------------------------------------------------------------------------------
 Gather Motion 3:1  (slice2; segments: 3)
   ->  Hash Join
         Hash Cond: (bar.c = jazz.e)
         ->  Sequence
               ->  Shared Scan (share slice:id 2:0)
                     ->  Materialize
                           ->  Redistribute Motion 3:3  (slice1; segments: 3)
                                 Hash Key: foo.b
                                 ->  Seq Scan on foo
               ->  Hash Join
                     Hash Cond: (bar.c = share0_ref2.b)
                     ->  Seq Scan on bar
                     ->  Hash
                           ->  Append
                                 ->  Shared Scan (share slice:id 2:0)
                                 ->  Shared Scan (share slice:id 2:0)
         ->  Hash
               ->  Seq Scan on jazz
                     Filter: (e = f)
 Optimizer: Pivotal Optimizer (GPORCA)
(20 rows)

SET statement_timeout = '15s';
:qry ;
 a | b | c | d | e | f 
---+---+---+---+---+---
 1 | 2 | 2 | 2 | 2 | 2
 1 | 2 | 2 | 2 | 2 | 2
(2 rows)

RESET statement_timeout;
SELECT COUNT(*)
FROM (SELECT *,
        (
        WITH cte AS (SELECT * FROM jazz WHERE jazz.e = bar.c)
        SELECT 1 FROM cte c1, cte c2
        )
      FROM bar) as s;
 count 
-------
   100
(1 row)

CREATE TABLE t1 (a int, b int);
NOTICE:  Table doesn't have 'DISTRIBUTED BY' clause -- Using column named 'a' as the Greenplum Database data distribution key for this table.
HINT:  The 'DISTRIBUTED BY' clause determines the distribution of data. Make sure column(s) chosen are the optimal data distribution key to minimize skew.
CREATE TABLE t2 (a int);
NOTICE:  Table doesn't have 'DISTRIBUTED BY' clause -- Using column named 'a' as the Greenplum Database data distribution key for this table.
HINT:  The 'DISTRIBUTED BY' clause determines the distribution of data. Make sure column(s) chosen are the optimal data distribution key to minimize skew.
-- ORCA plan contains a Shared Scan producer with a unsorted Motion below it
EXPLAIN (COSTS OFF)
WITH cte AS (SELECT * FROM t1 WHERE random() < 0.1 LIMIT 10) SELECT a, 1, 1 FROM cte JOIN t2 USING (a);
                                 QUERY PLAN                                 
----------------------------------------------------------------------------
 Sequence
   ->  Shared Scan (share slice:id 0:0)
         ->  Materialize
               ->  Limit
                     ->  Gather Motion 3:1  (slice3; segments: 3)
                           ->  Seq Scan on t1
                                 Filter: (random() < '0.1'::double precision)
   ->  Result
         ->  Gather Motion 3:1  (slice2; segments: 3)
               ->  Hash Join
                     Hash Cond: (share0_ref2.a = t2.a)
                     ->  Redistribute Motion 1:3  (slice1)
                           Hash Key: share0_ref2.a
                           ->  Result
                                 ->  Shared Scan (share slice:id 1:0)
                     ->  Hash
                           ->  Seq Scan on t2
 Optimizer: Pivotal Optimizer (GPORCA)
(18 rows)

-- This functions returns one more column than expected.
CREATE OR REPLACE FUNCTION col_mismatch_func1() RETURNS TABLE (field1 int, field2 int)
LANGUAGE 'plpgsql' VOLATILE STRICT AS
$$
DECLARE
   v_qry text;
BEGIN
   v_qry := 'WITH cte AS (SELECT * FROM t1 WHERE random() < 0.1 LIMIT 10) SELECT a, 1 , 1 FROM cte JOIN t2 USING (a)';
  RETURN QUERY EXECUTE v_qry;
END
$$;
-- This should only ERROR and should not SIGSEGV
SELECT col_mismatch_func1();
NOTICE:  An ERROR must have happened. Stopping a Shared Scan.
ERROR:  structure of query does not match function result type
DETAIL:  Number of returned columns (3) does not match expected column count (2).
CONTEXT:  PL/pgSQL function col_mismatch_func1() line 6 at RETURN QUERY
-- ORCA plan contains a Shared Scan producer with a sorted Motion below it
EXPLAIN (COSTS OFF)
WITH cte AS (SELECT * FROM t1 WHERE random() < 0.1 ORDER BY b LIMIT 10) SELECT a, 1, 1 FROM cte JOIN t2 USING (a);
                                    QUERY PLAN                                    
----------------------------------------------------------------------------------
 Sequence
   ->  Shared Scan (share slice:id 0:0)
         ->  Materialize
               ->  Limit
                     ->  Gather Motion 3:1  (slice3; segments: 3)
                           Merge Key: t1.b
                           ->  Sort
                                 Sort Key: t1.b
                                 ->  Seq Scan on t1
                                       Filter: (random() < '0.1'::double precision)
   ->  Result
         ->  Gather Motion 3:1  (slice2; segments: 3)
               ->  Hash Join
                     Hash Cond: (share0_ref2.a = t2.a)
                     ->  Redistribute Motion 1:3  (slice1)
                           Hash Key: share0_ref2.a
                           ->  Result
                                 ->  Shared Scan (share slice:id 1:0)
                     ->  Hash
                           ->  Seq Scan on t2
 Optimizer: Pivotal Optimizer (GPORCA)
(21 rows)

--- This functions returns one more column than expected.
CREATE OR REPLACE FUNCTION col_mismatch_func2() RETURNS TABLE (field1 int, field2 int)
    LANGUAGE 'plpgsql' VOLATILE STRICT AS
$$
DECLARE
    v_qry text;
BEGIN
    v_qry := 'WITH cte AS (SELECT * FROM t1 WHERE random() < 0.1 ORDER BY b LIMIT 10) SELECT a, 1 , 1 FROM cte JOIN t2 USING (a)';
    RETURN QUERY EXECUTE v_qry;
END
$$;
-- This should only ERROR and should not SIGSEGV
SELECT col_mismatch_func2();
NOTICE:  An ERROR must have happened. Stopping a Shared Scan.
ERROR:  structure of query does not match function result type
DETAIL:  Number of returned columns (3) does not match expected column count (2).
CONTEXT:  PL/pgSQL function col_mismatch_func2() line 6 at RETURN QUERY
-- https://github.com/greenplum-db/gpdb/issues/12701
-- Disable cte sharing in subquery
drop table if exists pk_list;
NOTICE:  table "pk_list" does not exist, skipping
create table pk_list (id int, schema_name varchar, table_name varchar) distributed by (id);
drop table if exists calender;
NOTICE:  table "calender" does not exist, skipping
create table calender (id int, data_hour timestamp) distributed by (id);
explain (costs off)
with
	tbls as (select distinct schema_name, table_name as table_nm from pk_list),
	tbls_daily_report_23 as (select unnest(string_to_array('mart_cm.card' ,',')) as table_nm_23),
	tbls_w_onl_actl_data as (select unnest(string_to_array('mart_cm.cont_resp,mart_cm.card', ',')) as table_nm_onl_act)
select  data_hour, stat.schema_name as schema_nm, dt.table_nm
from (
	select * from calender c
	cross join tbls
) dt
inner join (
	select tbls.schema_name, tbls.table_nm as table_name
	from tbls tbls
) stat on dt.table_nm = stat.table_name
where
	(data_hour = date_trunc('day',data_hour) and stat.schema_name || '.' ||stat.table_name not in (select table_nm_23 from tbls_daily_report_23))
	and (stat.schema_name || '.' ||stat.table_name not in (select table_nm_onl_act from tbls_w_onl_actl_data))
	or (stat.schema_name || '.' ||stat.table_name in (select table_nm_onl_act from tbls_w_onl_actl_data));
                                                                           QUERY PLAN                                                                            
-----------------------------------------------------------------------------------------------------------------------------------------------------------------
 Gather Motion 3:1  (slice11; segments: 3)
   ->  Hash Join
         Hash Cond: ((dt.table_nm)::text = (stat.table_name)::text)
         Join Filter: (((dt.data_hour = date_trunc('day'::text, dt.data_hour)) AND (NOT (hashed SubPlan 1)) AND (NOT (hashed SubPlan 2))) OR (hashed SubPlan 3))
         ->  Subquery Scan on dt
               ->  Nested Loop
                     ->  Seq Scan on calender c
                     ->  Materialize
                           ->  Broadcast Motion 3:3  (slice2; segments: 3)
                                 ->  HashAggregate
                                       Group Key: pk_list.schema_name, pk_list.table_name
                                       ->  Redistribute Motion 3:3  (slice1; segments: 3)
                                             Hash Key: pk_list.schema_name, pk_list.table_name
                                             ->  HashAggregate
                                                   Group Key: pk_list.schema_name, pk_list.table_name
                                                   ->  Seq Scan on pk_list
         ->  Hash
               ->  Broadcast Motion 3:3  (slice7; segments: 3)
                     ->  Subquery Scan on stat
                           Filter: (((NOT (hashed SubPlan 1)) AND (NOT (hashed SubPlan 2))) OR (hashed SubPlan 3))
                           ->  HashAggregate
                                 Group Key: pk_list_1.schema_name, pk_list_1.table_name
                                 ->  Redistribute Motion 3:3  (slice6; segments: 3)
                                       Hash Key: pk_list_1.schema_name, pk_list_1.table_name
                                       ->  HashAggregate
                                             Group Key: pk_list_1.schema_name, pk_list_1.table_name
                                             ->  Seq Scan on pk_list pk_list_1
                           SubPlan 1  (slice7; segments: 3)
                             ->  Materialize
                                   ->  Broadcast Motion 1:3  (slice3; segments: 1)
                                         ->  Result
                           SubPlan 2  (slice7; segments: 3)
                             ->  Materialize
                                   ->  Broadcast Motion 1:3  (slice4; segments: 1)
                                         ->  Result
                           SubPlan 3  (slice7; segments: 3)
                             ->  Materialize
                                   ->  Broadcast Motion 1:3  (slice5; segments: 1)
                                         ->  Result
         SubPlan 1  (slice11; segments: 3)
           ->  Materialize
                 ->  Broadcast Motion 1:3  (slice8; segments: 1)
                       ->  Result
         SubPlan 2  (slice11; segments: 3)
           ->  Materialize
                 ->  Broadcast Motion 1:3  (slice9; segments: 1)
                       ->  Result
         SubPlan 3  (slice11; segments: 3)
           ->  Materialize
                 ->  Broadcast Motion 1:3  (slice10; segments: 1)
                       ->  Result
 Optimizer: Postgres query optimizer
(52 rows)

-- Test the scenario which already opened many fds
-- start_ignore
RESET search_path;
-- end_ignore
\! mkdir -p /tmp/_gpdb_fault_inject_tmp_dir/
select gp_inject_fault('inject_many_fds_for_shareinputscan', 'skip', dbid) from gp_segment_configuration where role = 'p' and content = 0;
 gp_inject_fault 
-----------------
 Success:
(1 row)

-- borrow the test query in gp_aggregates
select case when ten < 5 then ten else ten * 2 end, count(distinct two), count(distinct four) from tenk1 group by 1;
 case | count | count 
------+-------+-------
    0 |     1 |     2
    1 |     1 |     2
    2 |     1 |     2
    3 |     1 |     2
    4 |     1 |     2
   10 |     1 |     2
   12 |     1 |     2
   14 |     1 |     2
   16 |     1 |     2
   18 |     1 |     2
(10 rows)

select gp_inject_fault('inject_many_fds_for_shareinputscan', 'reset', dbid) from gp_segment_configuration where role = 'p' and content = 0;
 gp_inject_fault 
-----------------
 Success:
(1 row)

\! rm -rf /tmp/_gpdb_fault_inject_tmp_dir/
-- To be able to pass this test, Shared Scan's Material node should be marked
-- as cross-slice. Previously, we processed all subplans separately from main
-- plan, which caused Material node not marked as cross-slice (upper main plan's
-- slice1 motion was ignored in processing).
-- No error like "ERROR:  cannot execute inactive Motion (nodeMotion.c:264)"
-- should be shown.
create table t1 (a int, b int, c int) distributed by (a);
explain (costs off)
with cte1 as (
  select max(c) as c from t1
), 
cte2 as (
  select d as c
  from generate_series(
    (select c from cte1) - 4,
    (select c from cte1), 1) d
)
select l.c from cte2 l
left join t1 u on l.c = u.c;
                                           QUERY PLAN                                           
------------------------------------------------------------------------------------------------
 Sequence
   ->  Shared Scan (share slice:id 0:0)
         ->  Materialize
               ->  Aggregate
                     ->  Gather Motion 3:1  (slice4; segments: 3)
                           ->  Seq Scan on t1 t1_1
   ->  Gather Motion 3:1  (slice3; segments: 3)
         ->  Hash Left Join
               Hash Cond: (generate_series.generate_series = t1.c)
               ->  Redistribute Motion 1:3  (slice1)
                     Hash Key: generate_series.generate_series
                     ->  Function Scan on generate_series
                           SubPlan 1  (slice1)
                             ->  Result
                                   ->  Result
                                         ->  Nested Loop Left Join
                                               Join Filter: true
                                               ->  Nested Loop Left Join
                                                     Join Filter: true
                                                     ->  Result
                                                     ->  Materialize
                                                           ->  Shared Scan (share slice:id 1:0)
                                               ->  Materialize
                                                     ->  Shared Scan (share slice:id 1:0)
                           SubPlan 2  (slice1)
                             ->  Result
                                   ->  Result
                                         ->  Nested Loop Left Join
                                               Join Filter: true
                                               ->  Nested Loop Left Join
                                                     Join Filter: true
                                                     ->  Result
                                                     ->  Materialize
                                                           ->  Shared Scan (share slice:id 1:0)
                                               ->  Materialize
                                                     ->  Shared Scan (share slice:id 1:0)
               ->  Hash
                     ->  Redistribute Motion 3:3  (slice2; segments: 3)
                           Hash Key: t1.c
                           ->  Seq Scan on t1
 Optimizer: Pivotal Optimizer (GPORCA)
(41 rows)

with cte1 as (
  select max(c) as c from t1
), 
cte2 as (
  select d as c
  from generate_series(
    (select c from cte1) - 4,
    (select c from cte1), 1) d
)
select l.c from cte2 l
left join t1 u on l.c = u.c;
 c 
---
(0 rows)

-- This case shows flacky count(*) result on pre-patched version. To make it
-- stable wrong we use new fault point.
-- Shared Scan consumer from slice1 not marked as cross-slice and not
-- initialized tuple store. We got '1' as the result of the query - only
-- Shared Scan from slice2 (the part below UNION) executed correctly.
-- From now, cross-slice interaction detection fixed for subplans and we have
-- stable '100' as a result.
create table t2(i int, j int) distributed by (i);
insert into t2 select i, i * 10 from generate_series(1, 10) i;
select gp_inject_fault('material_pre_tuplestore_flush', 'reset', dbid)
from gp_segment_configuration where role = 'p' and content = -1;
 gp_inject_fault 
-----------------
 Success:
(1 row)

select gp_inject_fault('material_pre_tuplestore_flush',
       'sleep', '', '', '', 1, 1, 5, dbid)
from gp_segment_configuration where role = 'p' and content = -1;       
 gp_inject_fault 
-----------------
 Success:
(1 row)

set optimizer_parallel_union = on;
explain (costs off)
with cte1 as (
  select max(j) as max_j from t2
)
select count(*) c
from (
  select s * 10 s
  from generate_series(1, (select max_j from cte1)) s
  union
  select max_j from cte1
) t;
                                                 QUERY PLAN                                                 
------------------------------------------------------------------------------------------------------------
 Sequence
   ->  Shared Scan (share slice:id 0:0)
         ->  Materialize
               ->  Aggregate
                     ->  Gather Motion 3:1  (slice4; segments: 3)
                           ->  Aggregate
                                 ->  Seq Scan on t2
   ->  Aggregate
         ->  Gather Motion 3:1  (slice3; segments: 3)
               ->  Aggregate
                     ->  HashAggregate
                           Group Key: ((generate_series.generate_series * 10))
                           ->  Append
                                 ->  Redistribute Motion 1:3  (slice1)
                                       Hash Key: ((generate_series.generate_series * 10))
                                       ->  Result
                                             ->  Function Scan on generate_series
                                                   SubPlan 1  (slice1)
                                                     ->  Result
                                                           ->  Nested Loop Left Join
                                                                 Join Filter: true
                                                                 ->  Result
                                                                 ->  Materialize
                                                                       ->  Shared Scan (share slice:id 1:0)
                                 ->  Redistribute Motion 1:3  (slice2)
                                       Hash Key: share0_ref3.max_j
                                       ->  Shared Scan (share slice:id 2:0)
 Optimizer: Pivotal Optimizer (GPORCA)
(28 rows)

with cte1 as (
  select max(j) as max_j from t2
)
select count(*) c
from (
  select s * 10 s
  from generate_series(1, (select max_j from cte1)) s
  union
  select max_j from cte1
) t;
  c  
-----
 100
(1 row)

reset optimizer_parallel_union;
select gp_inject_fault_infinite('material_pre_tuplestore_flush', 'reset', dbid)
from gp_segment_configuration where role = 'p' and content = -1;
 gp_inject_fault_infinite 
--------------------------
 Success:
(1 row)

