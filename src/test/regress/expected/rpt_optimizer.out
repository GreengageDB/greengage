--
-- Basic tests for replicated table
--
create schema rpt;
set search_path to rpt;
---------
-- INSERT
---------
create table foo (x int, y int) distributed replicated;
create table foo1(like foo) distributed replicated;
create table bar (like foo) distributed randomly;
create table bar1 (like foo) distributed by (x);
-- values --> replicated table 
-- random partitioned table --> replicated table
-- hash partitioned table --> replicated table
-- singleQE --> replicated table
-- replicated --> replicated table
insert into bar values (1, 1), (3, 1);
insert into bar1 values (1, 1), (3, 1);
insert into foo1 values (1, 1), (3, 1);
insert into foo select * from bar;
insert into foo select * from bar1;
insert into foo select * from bar order by x limit 1;
insert into foo select * from foo;
select * from foo order by x;
 x | y 
---+---
 1 | 1
 1 | 1
 1 | 1
 1 | 1
 1 | 1
 1 | 1
 3 | 1
 3 | 1
 3 | 1
 3 | 1
(10 rows)

select bar.x, bar.y from bar, (select * from foo) as t1 order by 1,2;
 x | y 
---+---
 1 | 1
 1 | 1
 1 | 1
 1 | 1
 1 | 1
 1 | 1
 1 | 1
 1 | 1
 1 | 1
 1 | 1
 3 | 1
 3 | 1
 3 | 1
 3 | 1
 3 | 1
 3 | 1
 3 | 1
 3 | 1
 3 | 1
 3 | 1
(20 rows)

select bar.x, bar.y from bar, (select * from foo order by x limit 1) as t1 order by 1,2;
 x | y 
---+---
 1 | 1
 3 | 1
(2 rows)

truncate foo;
truncate foo1;
truncate bar;
truncate bar1;
-- replicated table --> random partitioned table
-- replicated table --> hash partitioned table
insert into foo values (1, 1), (3, 1);
insert into bar select * from foo order by x limit 1;
insert into bar1 select * from foo order by x limit 1;
select * from foo order by x;
 x | y 
---+---
 1 | 1
 3 | 1
(2 rows)

select * from bar order by x;
 x | y 
---+---
 1 | 1
(1 row)

select * from bar1 order by x;
 x | y 
---+---
 1 | 1
(1 row)

drop table if exists foo;
drop table if exists foo1;
drop table if exists bar;
drop table if exists bar1;
--
-- CREATE UNIQUE INDEX
--
-- create unique index on non-distributed key.
create table foo (x int, y int) distributed replicated;
create table bar (x int, y int) distributed randomly;
-- success
create unique index foo_idx on foo (y);
-- should fail
create unique index bar_idx on bar (y);
ERROR:  UNIQUE and DISTRIBUTED RANDOMLY are incompatible
drop table if exists foo;
drop table if exists bar;
--
-- CREATE TABLE with both PRIMARY KEY and UNIQUE constraints
--
create table foo (id int primary key, name text unique) distributed replicated;
-- success
insert into foo values (1,'aaa');
insert into foo values (2,'bbb');
-- fail
insert into foo values (1,'ccc');
ERROR:  duplicate key value violates unique constraint "foo_pkey"  (seg0 127.0.1.1:6002 pid=287620)
DETAIL:  Key (id)=(1) already exists.
insert into foo values (3,'aaa');
ERROR:  duplicate key value violates unique constraint "foo_name_key"  (seg0 127.0.1.1:6002 pid=287620)
DETAIL:  Key (name)=(aaa) already exists.
drop table if exists foo;
--
-- CREATE TABLE
--
--
-- Like
CREATE TABLE parent (
        name            text,
        age                     int4,
        location        point
) distributed replicated;
CREATE TABLE child (like parent) distributed replicated;
CREATE TABLE child1 (like parent) DISTRIBUTED BY (name);
CREATE TABLE child2 (like parent);
NOTICE:  table doesn't have 'DISTRIBUTED BY' clause, defaulting to distribution columns from LIKE table
-- should be replicated table
\d child
       Table "rpt.child"
  Column  |  Type   | Modifiers 
----------+---------+-----------
 name     | text    | 
 age      | integer | 
 location | point   | 
Distributed Replicated

-- should distributed by name
\d child1
       Table "rpt.child1"
  Column  |  Type   | Modifiers 
----------+---------+-----------
 name     | text    | 
 age      | integer | 
 location | point   | 
Distributed by: (name)

-- should be replicated table
\d child2
       Table "rpt.child2"
  Column  |  Type   | Modifiers 
----------+---------+-----------
 name     | text    | 
 age      | integer | 
 location | point   | 
Distributed Replicated

drop table if exists parent;
drop table if exists child;
drop table if exists child1;
drop table if exists child2;
-- Inherits
CREATE TABLE parent_rep (
        name            text,
        age                     int4,
        location        point
) distributed replicated;
CREATE TABLE parent_part (
        name            text,
        age                     int4,
        location        point
) distributed by (name);
-- inherits from a replicated table, should fail
CREATE TABLE child (
        salary          int4,
        manager         name
) INHERITS (parent_rep) WITH OIDS;
ERROR:  cannot inherit from replicated table "parent_rep" to create table "child"
DETAIL:  An inheritance hierarchy cannot contain a mixture of distributed and non-distributed tables.
-- replicated table can not have parents, should fail
CREATE TABLE child (
        salary          int4,
        manager         name
) INHERITS (parent_part) WITH OIDS DISTRIBUTED REPLICATED;
ERROR:  INHERITS clause cannot be used with DISTRIBUTED REPLICATED clause
drop table if exists parent_rep;
drop table if exists parent_part;
drop table if exists child;
NOTICE:  table "child" does not exist, skipping
--
-- CTAS
--
-- CTAS from generate_series
create table foo as select i as c1, i as c2
from generate_series(1,3) i distributed replicated;
-- CTAS from replicated table 
create table bar as select * from foo distributed replicated;
select * from bar;
 c1 | c2 
----+----
  1 |  1
  2 |  2
  3 |  3
(3 rows)

drop table if exists foo;
drop table if exists bar;
-- CTAS from partition table table
create table foo as select i as c1, i as c2
from generate_series(1,3) i;
NOTICE:  Table doesn't have 'DISTRIBUTED BY' clause. Creating a NULL policy entry.
create table bar as select * from foo distributed replicated;
select * from bar;
 c1 | c2 
----+----
  1 |  1
  3 |  3
  2 |  2
(3 rows)

drop table if exists foo;
drop table if exists bar;
-- CTAS from singleQE 
create table foo as select i as c1, i as c2
from generate_series(1,3) i;
NOTICE:  Table doesn't have 'DISTRIBUTED BY' clause. Creating a NULL policy entry.
select * from foo;
 c1 | c2 
----+----
  1 |  1
  2 |  2
  3 |  3
(3 rows)

create table bar as select * from foo order by c1 limit 1 distributed replicated;
select * from bar;
 c1 | c2 
----+----
  1 |  1
(1 row)

drop table if exists foo;
drop table if exists bar;
-- Create view can work
create table foo(x int, y int) distributed replicated;
insert into foo values(1,1);
create view v_foo as select * from foo;
select * from v_foo;
 x | y 
---+---
 1 | 1
(1 row)

drop view v_foo;
drop table if exists foo;
---------
-- Alter
--------
-- Drop distributed key column
create table foo(x int, y int) distributed replicated;
create table bar(like foo) distributed by (x);
insert into foo values(1,1);
insert into bar values(1,1);
-- success
alter table foo drop column x;
-- fail
alter table bar drop column x;
NOTICE:  dropping a column that is part of the distribution policy forces a NULL distribution policy
drop table if exists foo;
drop table if exists foo1;
NOTICE:  table "foo1" does not exist, skipping
drop table if exists bar;
drop table if exists bar1;
NOTICE:  table "bar1" does not exist, skipping
-- Alter gp_distribution_policy
create table foo(x int, y int) distributed replicated;
create table foo1(x int, y int) distributed replicated;
create table bar(x int, y int) distributed by (x);
create table bar1(x int, y int) distributed randomly;
insert into foo select i,i from generate_series(1,10) i;
insert into foo1 select i,i from generate_series(1,10) i;
insert into bar select i,i from generate_series(1,10) i;
insert into bar1 select i,i from generate_series(1,10) i;
-- alter distribution policy of replicated table
alter table foo set distributed by (x);
alter table foo1 set distributed randomly;
-- alter a partitioned table to replicated table
alter table bar set distributed replicated;
alter table bar1 set distributed replicated;
-- verify the new policies
\d foo
       Table "rpt.foo"
 Column |  Type   | Modifiers 
--------+---------+-----------
 x      | integer | 
 y      | integer | 
Distributed by: (x)

\d foo1
       Table "rpt.foo1"
 Column |  Type   | Modifiers 
--------+---------+-----------
 x      | integer | 
 y      | integer | 
Distributed randomly

\d bar
       Table "rpt.bar"
 Column |  Type   | Modifiers 
--------+---------+-----------
 x      | integer | 
 y      | integer | 
Distributed Replicated

\d bar1
       Table "rpt.bar1"
 Column |  Type   | Modifiers 
--------+---------+-----------
 x      | integer | 
 y      | integer | 
Distributed Replicated

-- verify the reorganized data
select * from foo;
 x  | y  
----+----
  2 |  2
  3 |  3
  4 |  4
  7 |  7
  8 |  8
  1 |  1
  5 |  5
  6 |  6
  9 |  9
 10 | 10
(10 rows)

select * from foo1;
 x  | y  
----+----
  6 |  6
  8 |  8
  9 |  9
 10 | 10
  1 |  1
  3 |  3
  4 |  4
  5 |  5
  2 |  2
  7 |  7
(10 rows)

select * from bar;
 x  | y  
----+----
  2 |  2
  3 |  3
  4 |  4
  7 |  7
  8 |  8
  5 |  5
  6 |  6
  9 |  9
 10 | 10
  1 |  1
(10 rows)

select * from bar1;
 x  | y  
----+----
  6 |  6
  1 |  1
  4 |  4
  7 |  7
  8 |  8
  9 |  9
 10 | 10
  2 |  2
  3 |  3
  5 |  5
(10 rows)

-- alter back
alter table foo set distributed replicated;
alter table foo1 set distributed replicated;
alter table bar set distributed by (x);
alter table bar1 set distributed randomly;
-- verify the policies again
\d foo
       Table "rpt.foo"
 Column |  Type   | Modifiers 
--------+---------+-----------
 x      | integer | 
 y      | integer | 
Distributed Replicated

\d foo1
       Table "rpt.foo1"
 Column |  Type   | Modifiers 
--------+---------+-----------
 x      | integer | 
 y      | integer | 
Distributed Replicated

\d bar
       Table "rpt.bar"
 Column |  Type   | Modifiers 
--------+---------+-----------
 x      | integer | 
 y      | integer | 
Distributed by: (x)

\d bar1
       Table "rpt.bar1"
 Column |  Type   | Modifiers 
--------+---------+-----------
 x      | integer | 
 y      | integer | 
Distributed randomly

-- verify the reorganized data again
select * from foo;
 x  | y  
----+----
  1 |  1
  5 |  5
  6 |  6
  9 |  9
 10 | 10
  2 |  2
  3 |  3
  4 |  4
  7 |  7
  8 |  8
(10 rows)

select * from foo1;
 x  | y  
----+----
  2 |  2
  7 |  7
  6 |  6
  8 |  8
  9 |  9
 10 | 10
  1 |  1
  3 |  3
  4 |  4
  5 |  5
(10 rows)

select * from bar;
 x  | y  
----+----
  1 |  1
  5 |  5
  6 |  6
  9 |  9
 10 | 10
  2 |  2
  3 |  3
  4 |  4
  7 |  7
  8 |  8
(10 rows)

select * from bar1;
 x  | y  
----+----
  6 |  6
  8 |  8
  3 |  3
  1 |  1
  9 |  9
  4 |  4
  7 |  7
 10 | 10
  2 |  2
  5 |  5
(10 rows)

drop table if exists foo;
drop table if exists foo1;
drop table if exists bar;
drop table if exists bar1;
---------
-- UPDATE / DELETE
---------
create table foo(x int, y int) distributed replicated;
create table bar(x int, y int);
NOTICE:  Table doesn't have 'DISTRIBUTED BY' clause -- Using column named 'x' as the Greenplum Database data distribution key for this table.
HINT:  The 'DISTRIBUTED BY' clause determines the distribution of data. Make sure column(s) chosen are the optimal data distribution key to minimize skew.
insert into foo values (1, 1), (2, 1);
insert into bar values (1, 2), (2, 2);
update foo set y = 2 where y = 1;
select * from foo;
 x | y 
---+---
 1 | 2
 2 | 2
(2 rows)

update foo set y = 1 from bar where bar.y = foo.y;
select * from foo;
 x | y 
---+---
 2 | 1
 1 | 1
(2 rows)

delete from foo where y = 1;
select * from foo;
 x | y 
---+---
(0 rows)

-- Test replicate table within init plan
insert into foo values (1, 1), (2, 1);
select * from bar where exists (select * from foo);
 x | y 
---+---
 2 | 2
 1 | 2
(2 rows)

------
-- Test Current Of is disabled for replicated table
------
begin;
declare c1 cursor for select * from foo;
fetch 1 from c1;
 x | y 
---+---
 1 | 1
(1 row)

delete from foo where current of c1;
ERROR:  "foo" is not simply updatable
abort;
begin;
declare c1 cursor for select * from foo;
fetch 1 from c1;
 x | y 
---+---
 1 | 1
(1 row)

update foo set y = 1 where current of c1;
ERROR:  "foo" is not simply updatable
abort;
-----
-- Test updatable view works for replicated table
----
truncate foo;
truncate bar;
insert into foo values (1, 1);
insert into foo values (2, 2);
insert into bar values (1, 1);
create view v_foo as select * from foo where y = 1;
begin;
update v_foo set y = 2; 
select * from gp_dist_random('foo');
 x | y 
---+---
 2 | 2
 1 | 2
 2 | 2
 1 | 2
 2 | 2
 1 | 2
(6 rows)

abort;
update v_foo set y = 3 from bar where bar.y = v_foo.y; 
select * from gp_dist_random('foo');
 x | y 
---+---
 2 | 2
 1 | 3
 2 | 2
 1 | 3
 2 | 2
 1 | 3
(6 rows)

-- Test gp_segment_id for replicated table
-- gp_segment_id is ambiguous for replicated table, it's been disabled now.
create table baz (c1 int, c2 int) distributed replicated;
create table qux (c1 int, c2 int);
NOTICE:  Table doesn't have 'DISTRIBUTED BY' clause -- Using column named 'c1' as the Greenplum Database data distribution key for this table.
HINT:  The 'DISTRIBUTED BY' clause determines the distribution of data. Make sure column(s) chosen are the optimal data distribution key to minimize skew.
select gp_segment_id from baz;
ERROR:  column "gp_segment_id" does not exist
LINE 1: select gp_segment_id from baz;
               ^
select xmin from baz;
ERROR:  column "xmin" does not exist
LINE 1: select xmin from baz;
               ^
select xmax from baz;
ERROR:  column "xmax" does not exist
LINE 1: select xmax from baz;
               ^
select ctid from baz;
ERROR:  column "ctid" does not exist
LINE 1: select ctid from baz;
               ^
select * from baz where c2 = gp_segment_id;
ERROR:  column "gp_segment_id" does not exist
LINE 1: select * from baz where c2 = gp_segment_id;
                                     ^
select * from baz, qux where baz.c1 = gp_segment_id;
 c1 | c2 | c1 | c2 
----+----+----+----
(0 rows)

update baz set c2 = gp_segment_id;
ERROR:  column "gp_segment_id" does not exist
LINE 1: update baz set c2 = gp_segment_id;
                            ^
update baz set c2 = 1 where gp_segment_id = 1;
ERROR:  column "gp_segment_id" does not exist
LINE 1: update baz set c2 = 1 where gp_segment_id = 1;
                                    ^
update baz set c2 = 1 from qux where gp_segment_id = baz.c1;
insert into baz select i, i from generate_series(1, 1000) i;
vacuum baz;
vacuum full baz;
analyze baz;
-- Test dependencies check when alter table to replicated table
create view v_qux as select ctid from qux;
alter table qux set distributed replicated;
ERROR:  cannot set distributed replicated because other object depend on its system columns
DETAIL:  view v_qux depends on table qux column ctid
HINT:  system columns of replicated table will be exposed to users after altering, resolve dependencies first
drop view v_qux;
alter table qux set distributed replicated;
-- Test cursor for update also works for replicated table
create table cursor_update (c1 int, c2 int) distributed replicated;
insert into cursor_update select i, i from generate_series(1, 10) i;
begin;
declare c1 cursor for select * from cursor_update order by c2 for update;
fetch next from c1;
 c1 | c2 
----+----
  1 |  1
(1 row)

end;
-- Test MinMax path on replicated table
create table minmaxtest (x int, y int) distributed replicated;
create index on minmaxtest (x);
insert into minmaxtest select generate_series(1, 10);
set enable_seqscan=off;
select min(x) from minmaxtest;
 min 
-----
   1
(1 row)

-- Test replicated on partition table
-- should fail
CREATE TABLE foopart (a int4, b int4) DISTRIBUTED REPLICATED PARTITION BY RANGE (a) (START (1) END (10));
ERROR:  PARTITION BY clause cannot be used with DISTRIBUTED REPLICATED clause
CREATE TABLE foopart (a int4, b int4) PARTITION BY RANGE (a) (START (1) END (10)) ;
NOTICE:  Table doesn't have 'DISTRIBUTED BY' clause -- Using column named 'a' as the Greenplum Database data distribution key for this table.
HINT:  The 'DISTRIBUTED BY' clause determines the distribution of data. Make sure column(s) chosen are the optimal data distribution key to minimize skew.
NOTICE:  CREATE TABLE will create partition "foopart_1_prt_1" for table "foopart"
-- should fail
ALTER TABLE foopart SET DISTRIBUTED REPLICATED;
ERROR:  can't set the distribution policy of a partition table to REPLICATED
ALTER TABLE foopart_1_prt_1 SET DISTRIBUTED REPLICATED;
ERROR:  can't set the distribution policy of "foopart_1_prt_1"
HINT:  Distribution policy of a partition can only be the same as its parent's.
DROP TABLE foopart;
-- volatile replicated
-- General and segmentGeneral locus imply that if the corresponding
-- slice is executed in many different segments should provide the
-- same result data set. Thus, in some cases, General and segmentGeneral
-- can be treated like broadcast. But if the segmentGeneral and general
-- locus path contain volatile functions, they lose the property and
-- can only be treated as singleQE. The following cases are to check that
-- we correctly handle all these cases.
-- FIXME: ORCA does not consider this, we need to fix the cases when ORCA
-- consider this.
set optimizer = off;
set enable_bitmapscan = off;
create table t_hashdist(a int, b int, c int) distributed by (a);
create table t_replicate_volatile(a int, b int, c int) distributed replicated;
---- pushed down filter
explain (costs off) select * from t_replicate_volatile, t_hashdist where t_replicate_volatile.a > random();
                                 QUERY PLAN                                 
----------------------------------------------------------------------------
 Gather Motion 3:1  (slice2; segments: 3)
   ->  Nested Loop
         ->  Seq Scan on t_hashdist
         ->  Materialize
               ->  Broadcast Motion 1:3  (slice1; segments: 1)
                     ->  Result
                           ->  Seq Scan on t_replicate_volatile
                                 Filter: ((a)::double precision > random())
 Optimizer: Postgres query optimizer
(9 rows)

-- join qual
explain (costs off) select * from t_hashdist, t_replicate_volatile x, t_replicate_volatile y where x.a + y.a > random();
                                  QUERY PLAN                                   
-------------------------------------------------------------------------------
 Nested Loop
   ->  Result
         ->  Gather Motion 1:1  (slice1; segments: 1)
               ->  Nested Loop
                     Join Filter: (((x.a + y.a))::double precision > random())
                     ->  Seq Scan on t_replicate_volatile x
                     ->  Materialize
                           ->  Seq Scan on t_replicate_volatile y
   ->  Materialize
         ->  Gather Motion 3:1  (slice2; segments: 3)
               ->  Seq Scan on t_hashdist
 Optimizer: Postgres query optimizer
(12 rows)

-- sublink & subquery
explain (costs off) select * from t_hashdist where a > All (select random() from t_replicate_volatile);
                                     QUERY PLAN                                     
------------------------------------------------------------------------------------
 Gather Motion 3:1  (slice2; segments: 3)
   ->  Nested Loop Left Anti Semi (Not-In) Join
         Join Filter: ((t_hashdist.a)::double precision <= "NotIn_SUBQUERY".random)
         ->  Seq Scan on t_hashdist
         ->  Materialize
               ->  Broadcast Motion 1:3  (slice1; segments: 1)
                     ->  Subquery Scan on "NotIn_SUBQUERY"
                           ->  Seq Scan on t_replicate_volatile
 Optimizer: Postgres query optimizer
(9 rows)

explain (costs off) select * from t_hashdist where a in (select random()::int from t_replicate_volatile);
                            QUERY PLAN                            
------------------------------------------------------------------
 Gather Motion 3:1  (slice2; segments: 3)
   ->  Hash Semi Join
         Hash Cond: (t_hashdist.a = ((random())::integer))
         ->  Seq Scan on t_hashdist
         ->  Hash
               ->  Redistribute Motion 1:3  (slice1; segments: 1)
                     Hash Key: ((random())::integer)
                     ->  Seq Scan on t_replicate_volatile
 Optimizer: Postgres query optimizer
(9 rows)

-- subplan
explain (costs off, verbose) select * from t_hashdist left join t_replicate_volatile on t_hashdist.a > any (select random() from t_replicate_volatile);
                                                            QUERY PLAN                                                            
----------------------------------------------------------------------------------------------------------------------------------
 Gather Motion 3:1  (slice2; segments: 3)
   Output: t_hashdist.a, t_hashdist.b, t_hashdist.c, t_replicate_volatile.a, t_replicate_volatile.b, t_replicate_volatile.c
   ->  Nested Loop Left Join
         Output: t_hashdist.a, t_hashdist.b, t_hashdist.c, t_replicate_volatile.a, t_replicate_volatile.b, t_replicate_volatile.c
         Join Filter: (SubPlan 1)
         ->  Seq Scan on rpt.t_hashdist
               Output: t_hashdist.a, t_hashdist.b, t_hashdist.c
         ->  Materialize
               Output: t_replicate_volatile.a, t_replicate_volatile.b, t_replicate_volatile.c
               ->  Seq Scan on rpt.t_replicate_volatile
                     Output: t_replicate_volatile.a, t_replicate_volatile.b, t_replicate_volatile.c
         SubPlan 1  (slice2; segments: 3)
           ->  Materialize
                 Output: (random())
                 ->  Broadcast Motion 1:3  (slice1; segments: 1)
                       Output: (random())
                       ->  Seq Scan on rpt.t_replicate_volatile t_replicate_volatile_1
                             Output: random()
 Optimizer: Postgres query optimizer
 Settings: enable_bitmapscan=off, enable_seqscan=off, optimizer=off
(20 rows)

-- targetlist
explain (costs off) select * from t_hashdist cross join (select random () from t_replicate_volatile)x;
                          QUERY PLAN                           
---------------------------------------------------------------
 Gather Motion 3:1  (slice2; segments: 3)
   ->  Nested Loop
         ->  Seq Scan on t_hashdist
         ->  Materialize
               ->  Broadcast Motion 1:3  (slice1; segments: 1)
                     ->  Seq Scan on t_replicate_volatile
 Optimizer: Postgres query optimizer
(7 rows)

explain (costs off) select * from t_hashdist cross join (select a, sum(random()) from t_replicate_volatile group by a) x;
                           QUERY PLAN                           
----------------------------------------------------------------
 Gather Motion 3:1  (slice2; segments: 3)
   ->  Nested Loop
         ->  Seq Scan on t_hashdist
         ->  Materialize
               ->  Broadcast Motion 1:3  (slice1; segments: 1)
                     ->  HashAggregate
                           Group Key: t_replicate_volatile.a
                           ->  Seq Scan on t_replicate_volatile
 Optimizer: Postgres query optimizer
(9 rows)

explain (costs off) select * from t_hashdist cross join (select random() as k, sum(a) from t_replicate_volatile group by k) x;
                        QUERY PLAN                        
----------------------------------------------------------
 Nested Loop
   ->  Gather Motion 3:1  (slice1; segments: 3)
         ->  Seq Scan on t_hashdist
   ->  Materialize
         ->  Gather Motion 1:1  (slice2; segments: 1)
               ->  HashAggregate
                     Group Key: random()
                     ->  Seq Scan on t_replicate_volatile
 Optimizer: Postgres query optimizer
(9 rows)

explain (costs off) select * from t_hashdist cross join (select a, sum(b) as s from t_replicate_volatile group by a having sum(b) > random() order by a) x ;
                                              QUERY PLAN                                              
------------------------------------------------------------------------------------------------------
 Gather Motion 3:1  (slice2; segments: 3)
   ->  Nested Loop
         ->  Seq Scan on t_hashdist
         ->  Materialize
               ->  Broadcast Motion 1:3  (slice1; segments: 1)
                     ->  Sort
                           Sort Key: t_replicate_volatile.a
                           ->  HashAggregate
                                 Group Key: t_replicate_volatile.a
                                 Filter: ((sum(t_replicate_volatile.b))::double precision > random())
                                 ->  Seq Scan on t_replicate_volatile
 Optimizer: Postgres query optimizer
(12 rows)

-- insert
explain (costs off) insert into t_replicate_volatile select random() from t_replicate_volatile;
                                QUERY PLAN                                 
---------------------------------------------------------------------------
 Insert on t_replicate_volatile
   ->  Broadcast Motion 1:3  (slice1; segments: 1)
         ->  Subquery Scan on "*SELECT*"
               ->  Seq Scan on t_replicate_volatile t_replicate_volatile_1
 Optimizer: Postgres query optimizer
(5 rows)

explain (costs off) insert into t_replicate_volatile select random(), a, a from generate_series(1, 10) a;
                      QUERY PLAN                      
------------------------------------------------------
 Insert on t_replicate_volatile
   ->  Broadcast Motion 1:3  (slice1; segments: 1)
         ->  Subquery Scan on "*SELECT*"
               ->  Function Scan on generate_series a
 Optimizer: Postgres query optimizer
(5 rows)

create sequence seq_for_insert_replicated_table;
explain (costs off) insert into t_replicate_volatile select nextval('seq_for_insert_replicated_table');
                    QUERY PLAN                     
---------------------------------------------------
 Insert on t_replicate_volatile
   ->  Broadcast Motion 1:3  (slice1; segments: 1)
         ->  Subquery Scan on "*SELECT*"
               ->  Result
 Optimizer: Postgres query optimizer
(5 rows)

explain (costs off) select a from t_replicate_volatile union all select * from nextval('seq_for_insert_replicated_table');
                     QUERY PLAN                     
----------------------------------------------------
 Append
   ->  Gather Motion 1:1  (slice1; segments: 1)
         ->  Subquery Scan on "*SELECT* 1"
               ->  Seq Scan on t_replicate_volatile
   ->  Function Scan on nextval
 Optimizer: Postgres query optimizer
(6 rows)

-- insert into table with serial column
create table t_replicate_dst(id serial, i integer) distributed replicated;
create table t_replicate_src(i integer) distributed replicated;
insert into t_replicate_src select i from generate_series(1, 5) i;
explain (costs off, verbose) insert into t_replicate_dst (i) select i from t_replicate_src;
                                         QUERY PLAN                                          
---------------------------------------------------------------------------------------------
 Insert on rpt.t_replicate_dst
   ->  Broadcast Motion 1:3  (slice1; segments: 1)
         Output: ((nextval('t_replicate_dst_id_seq'::regclass))::integer), t_replicate_src.i
         ->  Seq Scan on rpt.t_replicate_src
               Output: nextval('t_replicate_dst_id_seq'::regclass), t_replicate_src.i
 Optimizer: Postgres query optimizer
 Settings: enable_bitmapscan=off, enable_seqscan=off, optimizer=off
(7 rows)

explain (costs off, verbose) with s as (select i from t_replicate_src group by i having random() > 0) insert into t_replicate_dst (i) select i from s;
                                       QUERY PLAN                                       
----------------------------------------------------------------------------------------
 Insert on rpt.t_replicate_dst
   ->  Broadcast Motion 1:3  (slice1; segments: 1)
         Output: ((nextval('t_replicate_dst_id_seq'::regclass))::integer), "*SELECT*".i
         ->  Subquery Scan on "*SELECT*"
               Output: nextval('t_replicate_dst_id_seq'::regclass), "*SELECT*".i
               ->  HashAggregate
                     Output: t_replicate_src.i
                     Group Key: t_replicate_src.i
                     Filter: (random() > '0'::double precision)
                     ->  Seq Scan on rpt.t_replicate_src
                           Output: t_replicate_src.i
 Optimizer: Postgres query optimizer
 Settings: enable_bitmapscan=off, enable_seqscan=off, optimizer=off
(13 rows)

insert into t_replicate_dst (i) select i from t_replicate_src;
select distinct id from gp_dist_random('t_replicate_dst') order by id;
 id 
----
  1
  2
  3
  4
  5
(5 rows)

-- update & delete
explain (costs off) update t_replicate_volatile set a = 1 where b > random();
ERROR:  could not devise a plan (cdbpath.c:2089)
explain (costs off) update t_replicate_volatile set a = 1 from t_replicate_volatile x where x.a + random() = t_replicate_volatile.b;
ERROR:  could not devise a plan (cdbpath.c:2089)
explain (costs off) update t_replicate_volatile set a = 1 from t_hashdist x where x.a + random() = t_replicate_volatile.b;
ERROR:  could not devise a plan (cdbpath.c:2089)
explain (costs off) delete from t_replicate_volatile where a < random();
ERROR:  could not devise a plan (cdbpath.c:2089)
explain (costs off) delete from t_replicate_volatile using t_replicate_volatile x where t_replicate_volatile.a + x.b < random();
ERROR:  could not devise a plan (cdbpath.c:2089)
explain (costs off) update t_replicate_volatile set a = random();
ERROR:  could not devise a plan (createplan.c:6507)
-- limit
explain (costs off) insert into t_replicate_volatile select * from t_replicate_volatile limit 1;
                                QUERY PLAN                                 
---------------------------------------------------------------------------
 Insert on t_replicate_volatile
   ->  Broadcast Motion 1:3  (slice1; segments: 1)
         ->  Limit
               ->  Seq Scan on t_replicate_volatile t_replicate_volatile_1
 Optimizer: Postgres query optimizer
(5 rows)

explain (costs off) select * from t_hashdist cross join (select * from t_replicate_volatile limit 1) x;
                           QUERY PLAN                           
----------------------------------------------------------------
 Gather Motion 3:1  (slice2; segments: 3)
   ->  Nested Loop
         ->  Seq Scan on t_hashdist
         ->  Materialize
               ->  Broadcast Motion 1:3  (slice1; segments: 1)
                     ->  Limit
                           ->  Seq Scan on t_replicate_volatile
 Optimizer: Postgres query optimizer
(8 rows)

create table rtbl (a int, b int, c int, t text) distributed replicated;
insert into t_hashdist values (1, 1, 1);
insert into rtbl values (1, 1, 1, 'rtbl');
-- The below tests used to do replicated table scan on entry db which contains empty data.
-- So a motion node is needed to gather replicated table on entry db.
-- See issue: https://github.com/greenplum-db/gpdb/issues/11945
-- 1. CTAS when join replicated table with catalog table
explain (costs off) create temp table tmp as select * from pg_class c join rtbl on c.relname = rtbl.t;
NOTICE:  Table doesn't have 'DISTRIBUTED BY' clause -- Using column(s) named 'relname' as the Greenplum Database data distribution key for this table.
HINT:  The 'DISTRIBUTED BY' clause determines the distribution of data. Make sure column(s) chosen are the optimal data distribution key to minimize skew.
                         QUERY PLAN                         
------------------------------------------------------------
 Redistribute Motion 1:3  (slice2)
   Hash Key: c.relname
   ->  Hash Join
         Hash Cond: ((c.relname)::text = rtbl.t)
         ->  Seq Scan on pg_class c
         ->  Hash
               ->  Gather Motion 1:1  (slice1; segments: 1)
                     ->  Seq Scan on rtbl
 Optimizer: Postgres query optimizer
(9 rows)

create temp table tmp as select * from pg_class c join rtbl on c.relname = rtbl.t;
NOTICE:  Table doesn't have 'DISTRIBUTED BY' clause -- Using column(s) named 'relname' as the Greenplum Database data distribution key for this table.
HINT:  The 'DISTRIBUTED BY' clause determines the distribution of data. Make sure column(s) chosen are the optimal data distribution key to minimize skew.
select count(*) from tmp; -- should contain 1 row
 count 
-------
     1
(1 row)

-- 2. Join hashed table with (replicated table join catalog) should return 1 row
explain (costs off) select relname from t_hashdist, (select * from pg_class c join rtbl on c.relname = rtbl.t) vtest where t_hashdist.a = vtest.a;
                                       QUERY PLAN                                       
----------------------------------------------------------------------------------------
 Gather Motion 3:1  (slice3; segments: 3)
   ->  Hash Join
         Hash Cond: (rtbl.a = t_hashdist.a)
         ->  Redistribute Motion 1:3  (slice2)
               Hash Key: rtbl.a
               ->  Hash Join
                     Hash Cond: ((c.relname)::text = rtbl.t)
                     ->  Index Only Scan using pg_class_relname_nsp_index on pg_class c
                     ->  Hash
                           ->  Gather Motion 1:1  (slice1; segments: 1)
                                 ->  Seq Scan on rtbl
         ->  Hash
               ->  Seq Scan on t_hashdist
 Optimizer: Postgres query optimizer
(14 rows)

select relname from t_hashdist, (select * from pg_class c join rtbl on c.relname = rtbl.t) vtest where t_hashdist.a = vtest.a;
 relname 
---------
 rtbl
(1 row)

-- 3. Join hashed table with (set operation on catalog and replicated table)
explain (costs off) select a from t_hashdist, (select oid from pg_class union all select a from rtbl) vtest;
                                     QUERY PLAN                                     
------------------------------------------------------------------------------------
 Gather Motion 3:1  (slice3; segments: 3)
   ->  Nested Loop
         ->  Broadcast Motion 1:3  (slice2)
               ->  Subquery Scan on vtest
                     ->  Append
                           ->  Index Only Scan using pg_class_oid_index on pg_class
                           ->  Gather Motion 1:1  (slice1; segments: 1)
                                 ->  Subquery Scan on "*SELECT* 2"
                                       ->  Seq Scan on rtbl
         ->  Materialize
               ->  Seq Scan on t_hashdist
 Optimizer: Postgres query optimizer
(12 rows)

reset optimizer;
reset enable_bitmapscan;
-- Github Issue 13532
create table t1_13532(a int, b int) distributed replicated;
create table t2_13532(a int, b int) distributed replicated;
create index idx_t2_13532 on t2_13532(b);
explain (costs off) select * from t1_13532 x, t2_13532 y where y.a < random() and x.b = y.b;
                        QUERY PLAN                        
----------------------------------------------------------
 Hash Join
   Hash Cond: (x.b = y.b)
   ->  Gather Motion 1:1  (slice1; segments: 1)
         ->  Seq Scan on t1_13532 x
   ->  Hash
         ->  Result
               ->  Gather Motion 1:1  (slice2; segments: 1)
                     ->  Bitmap Heap Scan on t2_13532 y
                           Filter: ((a)::double precision < random())
                           ->  Bitmap Index Scan on idx_t2_13532
 Optimizer: Postgres query optimizer
(8 rows)

set enable_bitmapscan = off;
explain (costs off) select * from t1_13532 x, t2_13532 y where y.a < random() and x.b = y.b;
                        QUERY PLAN                        
----------------------------------------------------------
 Hash Join
   Hash Cond: (x.b = y.b)
   ->  Gather Motion 1:1  (slice1; segments: 1)
         ->  Seq Scan on t1_13532 x
   ->  Hash
         ->  Result
               ->  Gather Motion 1:1  (slice2; segments: 1)
                     ->  Index Scan using idx_t2_13532 on t2_13532 y
                           Filter: ((a)::double precision < random())
 Optimizer: Postgres query optimizer
(8 rows)

-- ORCA
-- verify that JOIN derives the inner child distribution if the outer is tainted replicated (in this
-- case, the inner child is the hash distributed table, but the distribution is random because the
-- hash distribution key is not the JOIN key. we want to return the inner distribution because the
-- JOIN key determines the distribution of the JOIN output).
create table dist_tab (a integer, b integer) distributed by (a);
create table rep_tab (c integer) distributed replicated;
create index idx on dist_tab (b);
insert into dist_tab values (1, 2), (2, 2), (2, 1), (1, 1);
insert into rep_tab values (1), (2);
analyze dist_tab;
analyze rep_tab;
set optimizer_enable_hashjoin=off;
set enable_hashjoin=off;
set enable_nestloop=on;
explain select b from dist_tab where b in (select distinct c from rep_tab);
                                   QUERY PLAN                                    
---------------------------------------------------------------------------------
 Gather Motion 3:1  (slice1; segments: 3)  (cost=0.00..443.00 rows=4 width=4)
   ->  Nested Loop  (cost=0.00..443.00 rows=2 width=4)
         Join Filter: true
         ->  GroupAggregate  (cost=0.00..431.00 rows=2 width=4)
               Group Key: rep_tab.c
               ->  Sort  (cost=0.00..431.00 rows=2 width=4)
                     Sort Key: rep_tab.c
                     ->  Seq Scan on rep_tab  (cost=0.00..431.00 rows=2 width=4)
         ->  Index Scan using idx on dist_tab  (cost=0.00..12.00 rows=1 width=4)
               Index Cond: (b = rep_tab.c)
 Optimizer: Pivotal Optimizer (GPORCA)
(11 rows)

select b from dist_tab where b in (select distinct c from rep_tab);
 b 
---
 1
 2
 1
 2
(4 rows)

reset optimizer_enable_hashjoin;
reset enable_hashjoin;
reset enable_nestloop;
create table rand_tab (d integer) distributed randomly;
insert into rand_tab values (1), (2);
analyze rand_tab;
-- Table	Side		Derives
-- rep_tab	pdsOuter	EdtTaintedReplicated
-- rep_tab	pdsInner	EdtHashed
--
-- join derives EdtHashed
explain select c from rep_tab where c in (select distinct c from rep_tab);
                                     QUERY PLAN                                      
-------------------------------------------------------------------------------------
 Gather Motion 1:1  (slice1; segments: 1)  (cost=0.00..862.00 rows=2 width=4)
   ->  Hash Semi Join  (cost=0.00..862.00 rows=6 width=4)
         Hash Cond: (rep_tab.c = rep_tab_1.c)
         ->  Seq Scan on rep_tab  (cost=0.00..431.00 rows=6 width=4)
         ->  Hash  (cost=431.00..431.00 rows=6 width=4)
               ->  Seq Scan on rep_tab rep_tab_1  (cost=0.00..431.00 rows=6 width=4)
 Optimizer: Pivotal Optimizer (GPORCA)
(7 rows)

select c from rep_tab where c in (select distinct c from rep_tab);
 c 
---
 2
 1
(2 rows)

-- Table	Side		Derives
-- dist_tab	pdsOuter	EdtHashed
-- rep_tab	pdsInner	EdtTaintedReplicated 
--
-- join derives EdtHashed
explain select a from dist_tab where a in (select distinct c from rep_tab);
                                  QUERY PLAN                                  
------------------------------------------------------------------------------
 Gather Motion 3:1  (slice1; segments: 3)  (cost=0.00..862.00 rows=4 width=4)
   ->  Hash Semi Join  (cost=0.00..862.00 rows=2 width=4)
         Hash Cond: (dist_tab.a = rep_tab.c)
         ->  Seq Scan on dist_tab  (cost=0.00..431.00 rows=2 width=4)
         ->  Hash  (cost=431.00..431.00 rows=2 width=4)
               ->  Seq Scan on rep_tab  (cost=0.00..431.00 rows=2 width=4)
 Optimizer: Pivotal Optimizer (GPORCA)
(7 rows)

select a from dist_tab where a in (select distinct c from rep_tab);
 a 
---
 2
 2
 1
 1
(4 rows)

-- Table	Side		Derives
-- rand_tab	pdsOuter	EdtRandom
-- rep_tab	pdsInner	EdtTaintedReplicated
--
-- join derives EdtRandom
explain select d from rand_tab where d in (select distinct c from rep_tab);
                                  QUERY PLAN                                  
------------------------------------------------------------------------------
 Gather Motion 3:1  (slice1; segments: 3)  (cost=0.00..862.00 rows=2 width=4)
   ->  Hash Semi Join  (cost=0.00..862.00 rows=1 width=4)
         Hash Cond: (rand_tab.d = rep_tab.c)
         ->  Seq Scan on rand_tab  (cost=0.00..431.00 rows=1 width=4)
         ->  Hash  (cost=431.00..431.00 rows=2 width=4)
               ->  Seq Scan on rep_tab  (cost=0.00..431.00 rows=2 width=4)
 Optimizer: Pivotal Optimizer (GPORCA)
(7 rows)

select d from rand_tab where d in (select distinct c from rep_tab);
 d 
---
 1
 2
(2 rows)

-- Table	Side		Derives
-- rep_tab	pdsOuter	EdtTaintedReplicated
-- dist_tab	pdsInner	EdtHashed
--
-- join derives EdtHashed
explain select c from rep_tab where c in (select distinct a from dist_tab);
                                    QUERY PLAN                                    
----------------------------------------------------------------------------------
 Gather Motion 3:1  (slice1; segments: 3)  (cost=0.00..862.00 rows=2 width=4)
   ->  Hash Join  (cost=0.00..862.00 rows=1 width=4)
         Hash Cond: (dist_tab.a = rep_tab.c)
         ->  GroupAggregate  (cost=0.00..431.00 rows=1 width=4)
               Group Key: dist_tab.a
               ->  Sort  (cost=0.00..431.00 rows=2 width=4)
                     Sort Key: dist_tab.a
                     ->  Seq Scan on dist_tab  (cost=0.00..431.00 rows=2 width=4)
         ->  Hash  (cost=431.00..431.00 rows=2 width=4)
               ->  Seq Scan on rep_tab  (cost=0.00..431.00 rows=2 width=4)
 Optimizer: Pivotal Optimizer (GPORCA)
(11 rows)

select c from rep_tab where c in (select distinct a from dist_tab);
 c 
---
 2
 1
(2 rows)

-- Table	Side		Derives
-- rep_tab	pdsOuter	EdtTaintedReplicated
-- rand_tab	pdsInner	EdtHashed
--
-- join derives EdtHashed
explain select c from rep_tab where c in (select distinct d from rand_tab);
                                                 QUERY PLAN                                                 
------------------------------------------------------------------------------------------------------------
 Gather Motion 3:1  (slice2; segments: 3)  (cost=0.00..862.00 rows=2 width=4)
   ->  Hash Join  (cost=0.00..862.00 rows=1 width=4)
         Hash Cond: (rand_tab.d = rep_tab.c)
         ->  GroupAggregate  (cost=0.00..431.00 rows=1 width=4)
               Group Key: rand_tab.d
               ->  Sort  (cost=0.00..431.00 rows=1 width=4)
                     Sort Key: rand_tab.d
                     ->  Redistribute Motion 3:3  (slice1; segments: 3)  (cost=0.00..431.00 rows=1 width=4)
                           Hash Key: rand_tab.d
                           ->  Seq Scan on rand_tab  (cost=0.00..431.00 rows=1 width=4)
         ->  Hash  (cost=431.00..431.00 rows=2 width=4)
               ->  Seq Scan on rep_tab  (cost=0.00..431.00 rows=2 width=4)
 Optimizer: Pivotal Optimizer (GPORCA)
(13 rows)

select c from rep_tab where c in (select distinct d from rand_tab);
 c 
---
 1
 2
(2 rows)

-- test for optimizer_enable_replicated_table
explain (costs off) select * from rep_tab;
                QUERY PLAN
------------------------------------------
 Gather Motion 1:1  (slice1; segments: 1)
   ->  Seq Scan on rep_tab
 Optimizer: Pivotal Optimizer (GPORCA)
(3 rows)

set optimizer_enable_replicated_table=off;
set optimizer_trace_fallback=on;
explain (costs off) select * from rep_tab;
INFO:  GPORCA failed to produce a plan, falling back to planner
DETAIL:  Feature not supported: Use optimizer_enable_replicated_table to enable replicated tables
WARNING:  relcache reference leak: relation "rep_tab" not closed
                QUERY PLAN
------------------------------------------
 Gather Motion 1:1  (slice1; segments: 1)
   ->  Seq Scan on rep_tab
 Optimizer: Postgres query optimizer
(3 rows)

reset optimizer_trace_fallback;
reset optimizer_enable_replicated_table;
-- Ensure plan with Gather Motion node is generated.
drop table if exists t;
NOTICE:  table "t" does not exist, skipping
create table t (i int, j int) distributed replicated;
insert into t values (1, 2);
explain (costs off) select j, (select j) AS "Correlated Field" from t;
                QUERY PLAN                
------------------------------------------
 Gather Motion 1:1  (slice1; segments: 1)
   ->  Result
         ->  Seq Scan on t
         SubPlan 1  (slice1; segments: 1)
           ->  Result
                 ->  Result
 Optimizer: Pivotal Optimizer (GPORCA)
(7 rows)

select j, (select j) AS "Correlated Field" from t;
 j | Correlated Field 
---+------------------
 2 |                2
(1 row)

explain (costs off) select j, (select 5) AS "Uncorrelated Field" from t;
                QUERY PLAN                
------------------------------------------
 Gather Motion 1:1  (slice1; segments: 1)
   ->  Result
         ->  Nested Loop Left Join
               Join Filter: true
               ->  Seq Scan on t
               ->  Materialize
                     ->  Result
                           ->  Result
 Optimizer: Pivotal Optimizer (GPORCA)
(9 rows)

select j, (select 5) AS "Uncorrelated Field" from t;
 j | Uncorrelated Field 
---+--------------------
 2 |                  5
(1 row)

--
-- Check sub-selects with distributed replicated tables and volatile functions
--
drop table if exists t;
create table t (i int) distributed replicated;
create table t1 (a int) distributed by (a);
create table t2 (a int, b float) distributed replicated;
create or replace function f(i int) returns int language sql security definer as $$ select i; $$;
-- ensure we make gather motion when volatile functions in subplan
explain (costs off, verbose) select (select f(i) from t);
                     QUERY PLAN                      
-----------------------------------------------------
 Result
   Output: $0
   InitPlan 1 (returns $0)  (slice2)
     ->  Gather Motion 1:1  (slice1; segments: 1)
           Output: (f(i))
           ->  Seq Scan on rpt.t
                 Output: f(i)
 Optimizer: Postgres query optimizer
 Settings: enable_bitmapscan=off, enable_seqscan=off
(9 rows)

explain (costs off, verbose) select (select f(i) from t group by f(i));
                     QUERY PLAN                      
-----------------------------------------------------
 Result
   Output: $0
   InitPlan 1 (returns $0)  (slice2)
     ->  Gather Motion 1:1  (slice1; segments: 1)
           Output: (f(i))
           ->  HashAggregate
                 Output: (f(i))
                 Group Key: f(t.i)
                 ->  Seq Scan on rpt.t
                       Output: i, f(i)
 Optimizer: Postgres query optimizer
 Settings: enable_bitmapscan=off, enable_seqscan=off
(12 rows)

explain (costs off, verbose) select (select i from t group by i having f(i) > 0);
                     QUERY PLAN                      
-----------------------------------------------------
 Result
   Output: $0
   InitPlan 1 (returns $0)  (slice2)
     ->  Gather Motion 1:1  (slice1; segments: 1)
           Output: i
           ->  HashAggregate
                 Output: i
                 Group Key: t.i
                 Filter: (f(t.i) > 0)
                 ->  Seq Scan on rpt.t
                       Output: i
 Optimizer: Postgres query optimizer
 Settings: enable_bitmapscan=off, enable_seqscan=off
(13 rows)

-- ensure we do not make broadcast motion
explain (costs off, verbose) select * from t1 where a in (select random() from t where i=a group by i);
                             QUERY PLAN                             
--------------------------------------------------------------------
 Gather Motion 3:1  (slice1; segments: 3)
   Output: t1.a
   ->  Seq Scan on rpt.t1
         Output: t1.a
         Filter: (SubPlan 1)
         SubPlan 1  (slice1; segments: 1)
           ->  Result
                 Output: random(), t.i
                 Filter: (t.i = t1.a)
                 ->  Materialize
                       Output: t.i, t.i
                       ->  Seq Scan on rpt.t
                             Output: t.i, t.i
 Optimizer: Postgres query optimizer
 Settings: enable_bitmapscan=off, enable_seqscan=off
(15 rows)

explain (costs off, verbose) select * from t1 where a in (select random() from t where i=a);
                     QUERY PLAN                      
-----------------------------------------------------
 Gather Motion 3:1  (slice1; segments: 3)
   Output: t1.a
   ->  Seq Scan on rpt.t1
         Output: t1.a
         Filter: (SubPlan 1)
         SubPlan 1  (slice1; segments: 1)
           ->  Result
                 Output: random()
                 Filter: (t.i = t1.a)
                 ->  Materialize
                       Output: t.i
                       ->  Seq Scan on rpt.t
                             Output: t.i
 Optimizer: Postgres query optimizer
 Settings: enable_bitmapscan=off, enable_seqscan=off
(15 rows)

-- ensure we make broadcast motion when volatile function in deleting motion flow
explain (costs off, verbose) insert into t2 (a, b) select i, random() from t;
                     QUERY PLAN                      
-----------------------------------------------------
 Insert on rpt.t2
   ->  Broadcast Motion 1:3  (slice1; segments: 1)
         Output: t.i, (random())
         ->  Seq Scan on rpt.t
               Output: t.i, random()
 Optimizer: Postgres query optimizer
 Settings: enable_bitmapscan=off, enable_seqscan=off
(7 rows)

-- ensure we make broadcast motion when volatile function in correlated subplan qual
explain (costs off, verbose) select * from t1 where a in (select f(i) from t where i=a and f(i) > 0);
                                 QUERY PLAN                                  
-----------------------------------------------------------------------------
 Gather Motion 3:1  (slice2; segments: 3)
   Output: t1.a
   ->  Seq Scan on rpt.t1
         Output: t1.a
         Filter: (SubPlan 1)
         SubPlan 1  (slice2; segments: 3)
           ->  Result
                 Output: f(t.i)
                 ->  Result
                       Output: t.i
                       Filter: (t.i = t1.a)
                       ->  Materialize
                             Output: t.i, t.i
                             ->  Broadcast Motion 1:3  (slice1; segments: 1)
                                   Output: t.i, t.i
                                   ->  Seq Scan on rpt.t
                                         Output: t.i, t.i
                                         Filter: (f(t.i) > 0)
 Optimizer: Postgres query optimizer
 Settings: enable_bitmapscan=off, enable_seqscan=off
(20 rows)

-- ensure we do not break broadcast motion
explain (costs off, verbose) select * from t1 where 1 <= ALL (select i from t group by i having random() > 0);
                               QUERY PLAN                               
------------------------------------------------------------------------
 Gather Motion 3:1  (slice2; segments: 3)
   Output: t1.a
   ->  Result
         Output: t1.a
         One-Time Filter: (SubPlan 1)
         ->  Seq Scan on rpt.t1
               Output: t1.a
         SubPlan 1  (slice2; segments: 3)
           ->  Materialize
                 Output: t.i
                 ->  Broadcast Motion 1:3  (slice1; segments: 1)
                       Output: t.i
                       ->  HashAggregate
                             Output: t.i
                             Group Key: t.i
                             Filter: (random() > '0'::double precision)
                             ->  Seq Scan on rpt.t
                                   Output: t.i
 Optimizer: Postgres query optimizer
 Settings: enable_bitmapscan=off, enable_seqscan=off
(20 rows)

set gp_cte_sharing = on;
-- ensure that the volatile function is executed on one segment if it is in the CTE target list
explain (costs off, verbose) with cte as (
    select a * random() as a from t2
)
select * from cte join (select * from t1 join cte using(a)) b using(a);
                                     QUERY PLAN                                      
-------------------------------------------------------------------------------------
 Gather Motion 3:1  (slice4; segments: 3)
   Output: share0_ref1.a
   ->  Hash Join
         Output: share0_ref1.a
         Hash Cond: (share0_ref2.a = share0_ref1.a)
         ->  Hash Join
               Output: share0_ref2.a
               Hash Cond: ((t1.a)::double precision = share0_ref2.a)
               ->  Redistribute Motion 3:3  (slice1; segments: 3)
                     Output: t1.a
                     Hash Key: (t1.a)::double precision
                     ->  Seq Scan on rpt.t1
                           Output: t1.a
               ->  Hash
                     Output: share0_ref2.a
                     ->  Redistribute Motion 1:3  (slice2; segments: 1)
                           Output: share0_ref2.a
                           Hash Key: share0_ref2.a
                           ->  Shared Scan (share slice:id 2:0)
                                 Output: share0_ref2.a
         ->  Hash
               Output: share0_ref1.a
               ->  Redistribute Motion 1:3  (slice3; segments: 1)
                     Output: share0_ref1.a
                     Hash Key: share0_ref1.a
                     ->  Shared Scan (share slice:id 3:0)
                           Output: share0_ref1.a
                           ->  Materialize
                                 Output: (((t2.a)::double precision * random()))
                                 ->  Seq Scan on rpt.t2
                                       Output: ((t2.a)::double precision * random())
 Optimizer: Postgres query optimizer
 Settings: enable_bitmapscan=off, enable_seqscan=off, gp_cte_sharing=on
(33 rows)

set gp_cte_sharing = off;
explain (costs off, verbose) with cte as (
    select a, a * random() from t2
)
select * from cte join t1 using(a);
                                  QUERY PLAN                                   
-------------------------------------------------------------------------------
 Gather Motion 3:1  (slice2; segments: 3)
   Output: t2.a, (((t2.a)::double precision * random()))
   ->  Hash Join
         Output: t2.a, (((t2.a)::double precision * random()))
         Hash Cond: (t1.a = t2.a)
         ->  Seq Scan on rpt.t1
               Output: t1.a
         ->  Hash
               Output: t2.a, (((t2.a)::double precision * random()))
               ->  Redistribute Motion 1:3  (slice1; segments: 1)
                     Output: t2.a, (((t2.a)::double precision * random()))
                     Hash Key: t2.a
                     ->  Seq Scan on rpt.t2
                           Output: t2.a, ((t2.a)::double precision * random())
 Optimizer: Postgres query optimizer
 Settings: enable_bitmapscan=off, enable_seqscan=off, gp_cte_sharing=off
(16 rows)

reset gp_cte_sharing;
-- ensure that the volatile function is executed on one segment if it is in target list of subplan of multiset function
explain (costs off, verbose) select * from (
    SELECT count(*) as a FROM anytable_out( TABLE( SELECT random()::int from t2 ) )
) a join t1 using(a);
                                  QUERY PLAN                                  
------------------------------------------------------------------------------
 Gather Motion 3:1  (slice2; segments: 3)
   Output: (count(*))
   ->  Hash Join
         Output: (count(*))
         Hash Cond: (t1.a = (count(*)))
         ->  Seq Scan on rpt.t1
               Output: t1.a
         ->  Hash
               Output: (count(*))
               ->  Redistribute Motion 1:3  (slice1; segments: 1)
                     Output: (count(*))
                     Hash Key: (count(*))
                     ->  Aggregate
                           Output: count(*)
                           ->  Table Function Scan on pg_catalog.anytable_out
                                 Output: anytable_out
                                 ->  Seq Scan on rpt.t2
                                       Output: (random())::integer
 Optimizer: Postgres query optimizer
 Settings: enable_bitmapscan=off, enable_seqscan=off
(20 rows)

-- if there is a volatile function in the target list of a plan with the locus type
-- General or Segment General, then such a plan should be executed on single
-- segment, since it is assumed that nodes with such locus types will give the same
-- result on all segments, which is impossible for a volatile function.
-- start_ignore
drop table if exists d;
NOTICE:  table "d" does not exist, skipping
drop table if exists r;
NOTICE:  table "r" does not exist, skipping
-- end_ignore
create table r (a int, b int) distributed replicated;
create table d (b int, a int default 1) distributed by (b);
insert into d select * from generate_series(0, 20) j;
-- change distribution without reorganize
alter table d set distributed randomly;
insert into r values (1, 1), (2, 2), (3, 3);
with cte as (
    select a, b * random() as rand from r
)
select count(distinct(rand)) from cte join d on cte.a = d.a;
 count 
-------
     1
(1 row)

drop table r;
drop table d;
drop table if exists t;
drop table if exists t1;
drop table if exists t2;
drop function if exists f(i int);
-- Check that query containing 2 CTEs and replicated table can be optimized by ORCA
-- and it's execution does not produce problems like unconsumed producers or starved consumers
create table tbl2 (a numeric, b varchar(255), c numeric) distributed replicated;
create table tbl1 (a bigserial, b varchar(15), c varchar(15)) distributed replicated;
explain (analyze off, costs off, verbose off)
with
t1 as (select * from tbl1),
t2 as (select a, b from tbl2)
 select * from t1 p
  join t2 r on p.b = r.b
  join t2 r1 on p.c = r1.b;
                               QUERY PLAN                                
-------------------------------------------------------------------------
 Gather Motion 1:1  (slice1; segments: 1)
   ->  Sequence
         ->  Shared Scan (share slice:id 1:1)
               ->  Materialize
                     ->  Seq Scan on tbl2
         ->  Hash Join
               Hash Cond: ((tbl1.b)::text = (share1_ref2.b)::text)
               ->  Hash Join
                     Hash Cond: ((tbl1.c)::text = (share1_ref3.b)::text)
                     ->  Seq Scan on tbl1
                     ->  Hash
                           ->  Shared Scan (share slice:id 1:1)
               ->  Hash
                     ->  Shared Scan (share slice:id 1:1)
 Optimizer: Pivotal Optimizer (GPORCA)
(15 rows)

insert into tbl1 values(1,2,3);
insert into tbl2 values(1,2,3);
insert into tbl2 values(2,3,4);
with
t1 as (select * from tbl1),
t2 as (select a, b from tbl2)
 select * from t1 p
  join t2 r on p.b = r.b
  join t2 r1 on p.c = r1.b;
 a | b | c | a | b | a | b 
---+---+---+---+---+---+---
 1 | 2 | 3 | 1 | 2 | 2 | 3
(1 row)

-- start_ignore
drop schema rpt cascade;
NOTICE:  drop cascades to 13 other objects
DETAIL:  drop cascades to table foo
drop cascades to table bar
drop cascades to view v_foo
drop cascades to table baz
drop cascades to table qux
drop cascades to table cursor_update
drop cascades to table minmaxtest
drop cascades to table t_hashdist
drop cascades to table t_replicate_volatile
drop cascades to sequence seq_for_insert_replicated_table
drop cascades to table t_replicate_dst
drop cascades to table t_replicate_src
drop cascades to table rtbl
drop cascades to table t1_13532
drop cascades to table t2_13532
-- end_ignore
